{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e0a542",
   "metadata": {},
   "source": [
    "# Step A: Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de4220",
   "metadata": {},
   "source": [
    "## Step 1: Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8cd5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54b1c7",
   "metadata": {},
   "source": [
    "## Step 2:Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268ab41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data=pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cbdfc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0e8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping 1st 3 cols from dataset\n",
    "bank_data=bank_data.drop(['RowNumber','CustomerId' ,'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db9f591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a99b3a",
   "metadata": {},
   "source": [
    "## Step 3: To create Feature Matrix(X) and Dependent variable vector(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56c138c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=bank_data.iloc[:,:-1].values\n",
    "y=bank_data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7bec15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24658bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c948319",
   "metadata": {},
   "source": [
    "## Step 4- replacing missing values(no missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a70a4a",
   "metadata": {},
   "source": [
    "## Step 5: Encoding the categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e030f0",
   "metadata": {},
   "source": [
    "## Feature matrix using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774f66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(), [1,2])],remainder='passthrough')\n",
    "x=np.array(ct.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f413ba87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
       "       [0.0, 0.0, 1.0, ..., 0, 1, 112542.58],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
       "       [0.0, 1.0, 0.0, ..., 1, 0, 92888.52],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62cd5625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06148aa0",
   "metadata": {},
   "source": [
    "## Step 6: Splitting dataset into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb98095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b58e205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "xtrain=sc.fit_transform(xtrain)\n",
    "xtest=sc.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a8176f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99850112,  1.71490137, -0.57273139, ..., -1.55337352,\n",
       "         0.97725852,  0.42739449],\n",
       "       [ 1.00150113, -0.58312392, -0.57273139, ..., -1.55337352,\n",
       "        -1.02327069, -1.02548708],\n",
       "       [-0.99850112,  1.71490137, -0.57273139, ...,  0.64376017,\n",
       "         0.97725852, -0.94479772],\n",
       "       ...,\n",
       "       [ 1.00150113, -0.58312392, -0.57273139, ...,  0.64376017,\n",
       "         0.97725852, -0.14096853],\n",
       "       [ 1.00150113, -0.58312392, -0.57273139, ...,  0.64376017,\n",
       "         0.97725852,  0.01781218],\n",
       "       [-0.99850112,  1.71490137, -0.57273139, ...,  0.64376017,\n",
       "        -1.02327069, -1.15822478]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee9b271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98019606, -0.56118125, -0.57812007, ...,  0.65543311,\n",
       "         0.9426421 , -0.04925965],\n",
       "       [ 0.98019606, -0.56118125, -0.57812007, ...,  0.65543311,\n",
       "        -1.06084802, -0.58254072],\n",
       "       [ 0.98019606, -0.56118125, -0.57812007, ..., -1.52570869,\n",
       "         0.9426421 , -0.16313933],\n",
       "       ...,\n",
       "       [-1.02020406, -0.56118125,  1.72974448, ..., -1.52570869,\n",
       "         0.9426421 ,  1.07759708],\n",
       "       [-1.02020406,  1.78195548, -0.57812007, ...,  0.65543311,\n",
       "         0.9426421 ,  1.14197101],\n",
       "       [-1.02020406,  1.78195548, -0.57812007, ...,  0.65543311,\n",
       "         0.9426421 , -0.88821212]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c554ec",
   "metadata": {},
   "source": [
    "## Step B: Build Artificial Neural Net(ANN) Model Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee330e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0c11c9",
   "metadata": {},
   "source": [
    "# model with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b626d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3c1f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first hidden layer\n",
    "d1.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
    "#output layer\n",
    "d1.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a2f36",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d11f88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b708d0",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c855c35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4772 - accuracy: 0.7995 - val_loss: 0.4477 - val_accuracy: 0.8045\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8117 - val_loss: 0.4285 - val_accuracy: 0.8105\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8171 - val_loss: 0.4144 - val_accuracy: 0.8200\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8246 - val_loss: 0.4006 - val_accuracy: 0.8310\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8307 - val_loss: 0.3895 - val_accuracy: 0.8395\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8361 - val_loss: 0.3780 - val_accuracy: 0.8415\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8425 - val_loss: 0.3696 - val_accuracy: 0.8470\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8445 - val_loss: 0.3641 - val_accuracy: 0.8470\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8480 - val_loss: 0.3589 - val_accuracy: 0.8480\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8504 - val_loss: 0.3563 - val_accuracy: 0.8515\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8544 - val_loss: 0.3533 - val_accuracy: 0.8555\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8540 - val_loss: 0.3516 - val_accuracy: 0.8555\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8549 - val_loss: 0.3494 - val_accuracy: 0.8550\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8561 - val_loss: 0.3463 - val_accuracy: 0.8545\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8550 - val_loss: 0.3442 - val_accuracy: 0.8565\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8560 - val_loss: 0.3441 - val_accuracy: 0.8560\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8574 - val_loss: 0.3437 - val_accuracy: 0.8550\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8581 - val_loss: 0.3426 - val_accuracy: 0.8565\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8564 - val_loss: 0.3424 - val_accuracy: 0.8510\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8559 - val_loss: 0.3426 - val_accuracy: 0.8545\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8585 - val_loss: 0.3419 - val_accuracy: 0.8520\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8572 - val_loss: 0.3415 - val_accuracy: 0.8605\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8572 - val_loss: 0.3411 - val_accuracy: 0.8600\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8574 - val_loss: 0.3398 - val_accuracy: 0.8540\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8584 - val_loss: 0.3413 - val_accuracy: 0.8600\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8569 - val_loss: 0.3405 - val_accuracy: 0.8570\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8577 - val_loss: 0.3399 - val_accuracy: 0.8590\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8587 - val_loss: 0.3402 - val_accuracy: 0.8590\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8574 - val_loss: 0.3412 - val_accuracy: 0.8560\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8576 - val_loss: 0.3401 - val_accuracy: 0.8575\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8586 - val_loss: 0.3402 - val_accuracy: 0.8585\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8575 - val_loss: 0.3399 - val_accuracy: 0.8555\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8581 - val_loss: 0.3389 - val_accuracy: 0.8570\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8585 - val_loss: 0.3396 - val_accuracy: 0.8585\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8581 - val_loss: 0.3386 - val_accuracy: 0.8550\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8595 - val_loss: 0.3393 - val_accuracy: 0.8580\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8599 - val_loss: 0.3394 - val_accuracy: 0.8565\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8587 - val_loss: 0.3390 - val_accuracy: 0.8595\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8584 - val_loss: 0.3391 - val_accuracy: 0.8565\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8580 - val_loss: 0.3403 - val_accuracy: 0.8590\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8602 - val_loss: 0.3396 - val_accuracy: 0.8595\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8595 - val_loss: 0.3402 - val_accuracy: 0.8565\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8597 - val_loss: 0.3394 - val_accuracy: 0.8600\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8599 - val_loss: 0.3378 - val_accuracy: 0.8590\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8587 - val_loss: 0.3403 - val_accuracy: 0.8585\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8602 - val_loss: 0.3387 - val_accuracy: 0.8600\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8587 - val_loss: 0.3380 - val_accuracy: 0.8595\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8602 - val_loss: 0.3387 - val_accuracy: 0.8585\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8606 - val_loss: 0.3374 - val_accuracy: 0.8595\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8614 - val_loss: 0.3374 - val_accuracy: 0.8595\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8593 - val_loss: 0.3377 - val_accuracy: 0.8580\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8605 - val_loss: 0.3381 - val_accuracy: 0.8615\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8600 - val_loss: 0.3369 - val_accuracy: 0.8600\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8616 - val_loss: 0.3388 - val_accuracy: 0.8610\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8610 - val_loss: 0.3373 - val_accuracy: 0.8585\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8608 - val_loss: 0.3373 - val_accuracy: 0.8605\n",
      "Epoch 57/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8611 - val_loss: 0.3380 - val_accuracy: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8614 - val_loss: 0.3370 - val_accuracy: 0.8580\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8608 - val_loss: 0.3366 - val_accuracy: 0.8620\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8614 - val_loss: 0.3362 - val_accuracy: 0.8595\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8601 - val_loss: 0.3377 - val_accuracy: 0.8590\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8614 - val_loss: 0.3367 - val_accuracy: 0.8610\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8595 - val_loss: 0.3370 - val_accuracy: 0.8590\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8599 - val_loss: 0.3381 - val_accuracy: 0.8610\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8606 - val_loss: 0.3363 - val_accuracy: 0.8610\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8604 - val_loss: 0.3375 - val_accuracy: 0.8605\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8601 - val_loss: 0.3378 - val_accuracy: 0.8625\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8610 - val_loss: 0.3373 - val_accuracy: 0.8605\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8612 - val_loss: 0.3367 - val_accuracy: 0.8615\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8601 - val_loss: 0.3379 - val_accuracy: 0.8610\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8611 - val_loss: 0.3369 - val_accuracy: 0.8600\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8600 - val_loss: 0.3366 - val_accuracy: 0.8620\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8606 - val_loss: 0.3364 - val_accuracy: 0.8595\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8604 - val_loss: 0.3349 - val_accuracy: 0.8605\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8615 - val_loss: 0.3366 - val_accuracy: 0.8615\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8597 - val_loss: 0.3378 - val_accuracy: 0.8615\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8620 - val_loss: 0.3356 - val_accuracy: 0.8605\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8610 - val_loss: 0.3359 - val_accuracy: 0.8615\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8611 - val_loss: 0.3359 - val_accuracy: 0.8625\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8597 - val_loss: 0.3370 - val_accuracy: 0.8600\n",
      "Epoch 81/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8605 - val_loss: 0.3353 - val_accuracy: 0.8620\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8611 - val_loss: 0.3366 - val_accuracy: 0.8625\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8616 - val_loss: 0.3352 - val_accuracy: 0.8615\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8608 - val_loss: 0.3348 - val_accuracy: 0.8625\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8611 - val_loss: 0.3372 - val_accuracy: 0.8615\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8608 - val_loss: 0.3373 - val_accuracy: 0.8630\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8609 - val_loss: 0.3354 - val_accuracy: 0.8635\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8614 - val_loss: 0.3351 - val_accuracy: 0.8615\n",
      "Epoch 89/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8608 - val_loss: 0.3365 - val_accuracy: 0.8635\n",
      "Epoch 90/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8609 - val_loss: 0.3353 - val_accuracy: 0.8600\n",
      "Epoch 91/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8606 - val_loss: 0.3346 - val_accuracy: 0.8625\n",
      "Epoch 92/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8606 - val_loss: 0.3367 - val_accuracy: 0.8605\n",
      "Epoch 93/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8616 - val_loss: 0.3352 - val_accuracy: 0.8625\n",
      "Epoch 94/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8597 - val_loss: 0.3364 - val_accuracy: 0.8605\n",
      "Epoch 95/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8612 - val_loss: 0.3355 - val_accuracy: 0.8615\n",
      "Epoch 96/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8611 - val_loss: 0.3366 - val_accuracy: 0.8605\n",
      "Epoch 97/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8606 - val_loss: 0.3345 - val_accuracy: 0.8600\n",
      "Epoch 98/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8608 - val_loss: 0.3345 - val_accuracy: 0.8630\n",
      "Epoch 99/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8625 - val_loss: 0.3365 - val_accuracy: 0.8635\n",
      "Epoch 100/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8610 - val_loss: 0.3369 - val_accuracy: 0.8630\n",
      "Epoch 101/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8615 - val_loss: 0.3367 - val_accuracy: 0.8615\n",
      "Epoch 102/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8610 - val_loss: 0.3366 - val_accuracy: 0.8625\n",
      "Epoch 103/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.8599 - val_loss: 0.3375 - val_accuracy: 0.8630\n",
      "Epoch 104/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8610 - val_loss: 0.3371 - val_accuracy: 0.8635\n",
      "Epoch 105/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3360 - accuracy: 0.8608 - val_loss: 0.3360 - val_accuracy: 0.8620\n",
      "Epoch 106/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8627 - val_loss: 0.3346 - val_accuracy: 0.8635\n",
      "Epoch 107/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8604 - val_loss: 0.3354 - val_accuracy: 0.8610\n",
      "Epoch 108/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8612 - val_loss: 0.3353 - val_accuracy: 0.8630\n",
      "Epoch 109/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8608 - val_loss: 0.3349 - val_accuracy: 0.8615\n",
      "Epoch 110/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3356 - accuracy: 0.8609 - val_loss: 0.3355 - val_accuracy: 0.8630\n",
      "Epoch 111/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8608 - val_loss: 0.3355 - val_accuracy: 0.8615\n",
      "Epoch 112/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8608 - val_loss: 0.3357 - val_accuracy: 0.8635\n",
      "Epoch 113/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8616 - val_loss: 0.3362 - val_accuracy: 0.8620\n",
      "Epoch 114/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8619 - val_loss: 0.3349 - val_accuracy: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3356 - accuracy: 0.8610 - val_loss: 0.3353 - val_accuracy: 0.8630\n",
      "Epoch 116/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8602 - val_loss: 0.3354 - val_accuracy: 0.8620\n",
      "Epoch 117/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8622 - val_loss: 0.3351 - val_accuracy: 0.8625\n",
      "Epoch 118/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8616 - val_loss: 0.3350 - val_accuracy: 0.8645\n",
      "Epoch 119/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8620 - val_loss: 0.3349 - val_accuracy: 0.8635\n",
      "Epoch 120/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8619 - val_loss: 0.3346 - val_accuracy: 0.8615\n",
      "Epoch 121/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8634 - val_loss: 0.3354 - val_accuracy: 0.8640\n",
      "Epoch 122/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3352 - accuracy: 0.8614 - val_loss: 0.3345 - val_accuracy: 0.8630\n",
      "Epoch 123/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.8614 - val_loss: 0.3358 - val_accuracy: 0.8620\n",
      "Epoch 00123: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e67ee22bb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
    "d1.fit(xtrain, ytrain, epochs=500, validation_data=(xtest,ytest),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c5ff1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.477199</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.447670</td>\n",
       "      <td>0.8045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.439426</td>\n",
       "      <td>0.811750</td>\n",
       "      <td>0.428465</td>\n",
       "      <td>0.8105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.425602</td>\n",
       "      <td>0.817125</td>\n",
       "      <td>0.414426</td>\n",
       "      <td>0.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.413287</td>\n",
       "      <td>0.824625</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.8310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.399760</td>\n",
       "      <td>0.830750</td>\n",
       "      <td>0.389476</td>\n",
       "      <td>0.8395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.335359</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.334866</td>\n",
       "      <td>0.8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.335676</td>\n",
       "      <td>0.861875</td>\n",
       "      <td>0.334612</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.335853</td>\n",
       "      <td>0.863375</td>\n",
       "      <td>0.335384</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.335190</td>\n",
       "      <td>0.861375</td>\n",
       "      <td>0.334518</td>\n",
       "      <td>0.8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.335805</td>\n",
       "      <td>0.861375</td>\n",
       "      <td>0.335816</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    0.477199  0.799500  0.447670        0.8045\n",
       "1    0.439426  0.811750  0.428465        0.8105\n",
       "2    0.425602  0.817125  0.414426        0.8200\n",
       "3    0.413287  0.824625  0.400635        0.8310\n",
       "4    0.399760  0.830750  0.389476        0.8395\n",
       "..        ...       ...       ...           ...\n",
       "118  0.335359  0.862000  0.334866        0.8635\n",
       "119  0.335676  0.861875  0.334612        0.8615\n",
       "120  0.335853  0.863375  0.335384        0.8640\n",
       "121  0.335190  0.861375  0.334518        0.8630\n",
       "122  0.335805  0.861375  0.335816        0.8620\n",
       "\n",
       "[123 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses1=pd.DataFrame(d1.history.history)\n",
    "losses1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eca7839f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyy0lEQVR4nO3deZwcdZ3/8denqvqa6blnMpOZ3Pc1SYAQrgUCLgoYDuUXA+JBIPBTl0N0VS6VRdRddd1ddxFk/QmEBQOCcSMgCBIICMEECAk5CCHkmBxzXz09fVV9f3/0JCTkmoQZerrzeT4e85iuo6s+1dXz7ppvVX1bjDEopZTKflamC1BKKdU3NNCVUipHaKArpVSO0EBXSqkcoYGulFI5wsnUisvLy82IESMytXqllMpKr7/+epMxpuJA0zIW6CNGjGDFihWZWr1SSmUlEdlysGna5KKUUjlCA10ppXKEBrpSSuUIDXSllMoRGuhKKZUjNNCVUipHaKArpVSOyNh16EqpgcPr7sZtb8cpLUX8/j3j3UgXVjCAOH0fFcYYTHc3blsbEghgFxUddj0mlcLt6ABjcMrKPhifSODFYtiFhUdeRzKJG4nglJQc0fPcjg66Xn6Z5I4d+IYNIzByJP5RoxDb3lNT9LVXsIpK8Y8ciV1QcMS1HSkN9AHAGIOIZLqMzDMGUjHoaoSOHRBtgSEnQjh9U5wXjRJ56SX8Q4cSGDcOEYP77jJSG5bhHz4cKayCYDH48nBjSWKrV9G96m2c4hBFfzcVIYUJlND+yjq8aJTCk8bhBIGyMekfDGbXOpIb3sJ3/N8jRYPTZaVSxN97D5NMgZvE8lnY5ZVg2XT99a9EXlyK+HyETzmevDGDSDXsIrFlG8YKYA+dgFM1BF9lKXaiHrc7Sde6XcQ2vkf4jDMITZ6A4IETwuvqJLHqFRJrluO5NpSOgkAIf4Hgj72NiXeT6C4g3uaR2LaTxPad+IcOp2juFwnW1hJbu47Iiy+QfP893OYGvO4I/vIC/OV5eK5FoimGG4nhqyzHX1VKqq2T7nWbiG3cjInHAbBCQfKnjycwpJyuNVvoXvcevuoqKq76PAVnnkLkb6voeP5l7MJCwmecRmBoFV3PP03XsuXY5RWEL5hLaPrxJLduIrHqZSyfEBgyGF9NNVJQAXmlRFevo+XBh4m8/ComkdznLWCXFBIaM5TQqEEY15Bo6CTR1IHbGcNtb8fr6Ngzr1NZQWjSOFI7thJ7rw7jGvInD6Xoks+TbGknsuR5krsaCI4fTWjKFFKNzURXr8Vtayc4cRyhCeOIb9pCZNlyvEgXvsoyQiPK8aJREvVtpDpiIAJi4wyqwD9qNHZhGG/HRlK7ttNd1wnevt8nYYf9hCcNxnJSdLyxHTe217SiMP7qMgLV5RRd8jnyzr6wz/+EJFNfcDFjxgyT03eKuql0MIUHgWXvP72rCVo3E+8KsfX/Xovb3o5dXExoymQG/+AH2MXFGDdF83/9nOjrKyn50pWEzz4bk0jQtWwZifVrINoM8XbCs2YROPGT4ATSyzYGr7mOxOpXEdsjMP1MKKhKT+tuhWgzbms9iY0bCYwbi1VQCrEO2PEmXt1bSLwFSXSC7SfaNYjOd7rJmz6J8GknIXnFJNsTdL60jNSGFbjb1uM4XRSfOBhfdQ2Jlm6aXqgj0RTHX2zjL3GwKwZhVw3H64oRXbWGeF0rEgxhl5bhlIQJBNpw3O2k2qIkOgQ3kW4JFIFAcYrQ5HHE2oI0LdmCG02/X8UBy/FwY+l5nbwURSO6sf0eke1Bok1+MB98SAZLEpSO76LlnXxirT1HoGLIr4rjD6ewgzaJTovIDh9ewsL2u4RH52GcPCLvtuPFvIPuajtkwDV76j7ofEEXN27tU5e/IIUTckl0OqS6D/A+OQhxPPzh9POMK1g+wUsawODkudgBD7EgGbFx4zZg8OW52EGPZFd6nNiGYEmCYGkSJ+hh+z1irT4iO4Kkum2CJQnyq+JEdgaJt/nAMuAJdtDFpAQv9cH2Onkp3ISFSR38NbD8HpZtSHXbWD6PouHdOPkudkkZJhbFjXSTjDh0N/tIdPpADL58F39+um67sADbjmFbEYwndDf7ibX4cIIeocE+JJRP+5oOUtH0cWqgJEGgIEV3i59kxMFyPEJlSeygS3dzepwddAkPjuEvdIk1+4i1+LD8Zs9+Eek5zoja6X0Ut7D9Hk7IIlQJ4YpWAkVJEhGHeLSAru02ke02JiWEJ5RQdMZ0aN1MYsNa4m2GRMQh0ekw6MuzKb7x573e3/vse5HXjTEzDjhNA31/xnVJbtvG7tfGys/HKS5GbAua34WGtbipIJH32knUNWA7SWwris9uxu9tRlrfpXtLC/E2m4KRPvxTT4MhMyC/HJwQrP8jrH8KL57i/WfLcRM+iiaFcLs9OjbE8RVZDD3Pofm1dto2hrB8Hl7Swil0cKMuJrX/PgtXx8kbFqK7PkWsAZJdH/xh5VXGKZ3o4caSdDfZdDf5ibc7YAQnL0XFlE4ChSma3wnTWRfEDlnkDQmR6kzQvTMFGEDwhVP48l2i9X5AQAx2yMLtNiCQX2PTtd1FLAhWBUi2p0h1uvvUaQcgOKQIE+/C7ewmGbXxkh/UagV82EX5YDuYRIpUc9sH2zEiTNn5x+N2RuneuAPPtQmMn4xVM57OJS/RtfxN8AyB4ZWEp40mr3YsodpJRFa+R8N/P0qquQ2nrJhBXziH4LBK2l7dQOS11aRaWvG6YtjhAOEZEwlNmUx0+TK63nofxBAenUf+mGKs4nIIleK5Fm5HBBPrJm9kEcFBPvCH6W4J0L0jhq+yEv/wYYgbwd26ltSuOhIRH4k2g1MQIDwqQCC/i86NMdrfbMBLugQGFeCvCOMfMw7/pBOwrW7YugzTuIlEYAIJhiLhYvylfvwlFk5ZMWI5uDs20PHMn+l+t468MZWET5iIUz0yfSCRXwF5ZbhJByGO1b0LIg3gz8dNWlg+B/GikOwGy0n/BAowoRK8hMGWKEQaMKkkncs3EF27hfC0EeRPHIxJpYhu2E6ioZP8U07FP/UUTP16os/8jvh77+MfNQ5f7al4np/Eth0kd+zEbWnG7WgnNKqK4jOnYhVXwPBTobA6nZotm6D1fQiV4Lp+xDJYqc70f2uN66FpA4SKoWIiFA0BN5H+j65yMgyeDiKYxneJPX0fTlkRvlFTIFQC3W24TTuxQn7EF0i/d70UbqQTK+BHLAEnCCXDoXh4eh1OML389rp0Te116ToQGPP3UHN8+kDNTUGqG/zh9BEI6f/oTDKJFQp98MZPdkPb1g8yJr8CySs9qnzSQD8C0b+9xq5b/5H4tqb9plmOwfa7WD5DvMPZ50jrYKygQ83ZhnDhNrrq/bS+m4+/xKFo9rk0vthA56tvM+xL48gfnj667trcRd0j7+Ol0kd9ZReeQsWcWXQ8/STtf12PvyxE+LjRhKbWIhVjce0S2h7/Pa1PvowbieMUBwmNKCU4chj+sRNINLbRuuhZUm1d6XpCfkJjhxKaNAb/kGpaFj9PbEO6awgrnE/RxZ/B6+wg+sabiONQ8vnLKDprBl0vLaXl0T/itrdTeMpkik4dj+/E85FB40ls20bLgw/S+ednCc86k/KvfhVfZSXQ0zbb2orbUIcEAvgnTP2geSkewbhJ3JghuX0HTuUgnIqKfZqfUo2NdL/1FnZREaEZMw7ZNJVqbMSkUvgGD95vmhuJEP3b38ibeRJ2OH+/6SaVAstCrA8+XHb/bWhzmBpINNB7IbFtG40/+i4dS17DyUtRNiOEHbAgFcMjH5ciXJOP6+XjJm0CQwcRHl9IqCqAG6zBtcpIRgMk6nbgdXcTmjoVp6KC7d/6NvENGwhOmkjs7TXYhQW4XVFw00eug/7xm5TNn79PLbF33mHnLbdS9JnPUPqFy3tVvxeP43V24pSX7zfNJBJ0vfY3nMpBBEaP3nPSBtKhFXnhBVKNjRSe/+kDhp1SauDQQD8AYwyphkYS696g87e/ovWl9YgYSmuF8m99H+v4uXv+hfoovK4udtx6G9Hlyym7ej4ll12G19FB+x+fwIt1U/7Vr+oRoFKq1zTQSV+aVP+Tn9L2yCMYz4PdPwBiKJ5eRPlVX8B3+jwIhPt+/Xoli1KqDxwq0I+JyxZTra1s//qNRF97jcLTJuKjCdq24ASTBKb9HYHPfgdnzAn9WoOGuVKqv+VsoBvXpevll+l84QU6n30Or72dwZ8MU1z6FygZAeMug+O/BJWTMl2qUkr1iZwMdGMMO2+5lfb//V8kL4/8E4+jfNBKQoGtMGchjDu3T9rHlVJqIMnJQG99+GHa//d/Kbv6asrnnI216MvpG3k+/ziM+LtMl6eUUv0i5wI9+sYb1P/4nwnPmkXFp0YhD56fPsn5pcUwpH/byZVSKpNyKtDdzk62f/1GfNXVVF88BHnsy1AzA+b+DxTuf7OJUkrlkpzqPrfxF/9JqrGRmktGYC/7CUydC/Oe0jBXSh0TcibQY2vX0vrQQ5TMrCK0cyGcci1cfM8HHVYppVSOy4kmF+N57PqnO7DzHCpq3oCzb4PT/1GvZFFKHVNy4gi97dFH6X7rLSon12PPuhbO+JaGuVLqmJP1gR7f9D71P/oh+ZUxCmefD39/R6ZLUkqpjMjqQDfRTnZcMxeLBIMvn4F85m6wsnqTlFLqqGVv+rkpGv/hHGJ1nVR9+Sx88x/RE6BKqWNaVp4UNcbQfMe1NL/aTtEZUyn85j2ZLkkppTKuV0foInKuiLwjIhtF5KYDTB8mIktE5E0RWSUi5/d9qWnGdan/p9tpfORFCieGGPyfC/prVUoplVUOG+giYgN3AecBk4DLROTDXRTeBjxqjDkOuBT4ZV8XulvTXXfRuvBRSidEqP75fyIBbWZRSino3RH6TGCjMWaTMSYBLAQu+tA8BijseVwE7Oi7EvdV8tnzGHxKjMq5pyMjT+uv1SilVNbpTaDXANv2Gq7rGbe324EviEgd8BRw3YEWJCLXiMgKEVnR2Nh4FOWC885Cike0w9/fflTPV0qpXNVXV7lcBtxvjBkCnA88KCL7LdsYc68xZoYxZkZFRcXRremMb8Hlv4OKcR+pYKWUyjW9CfTtwNC9hof0jNvbVcCjAMaYV4EgsP/Xz/cFXxDGfKJfFq2UUtmsN4G+HBgrIiNFxE/6pOfiD82zFfgEgIhMJB3oR9emopRS6qgcNtCNMSngWuAZYB3pq1nWiMgdInJhz2zfBK4WkbeA3wJXGGNMfxWtlFJqf726scgY8xTpk517j/veXo/XAnrJiVJKZVD23vqvlFJqHxroSimVIzTQlVIqR2igK6VUjtBAV0qpHKGBrpRSOUIDXSmlcoQGulJK5QgNdKWUyhEa6EoplSM00JVSKkdooCulVI7QQFdKqRyhga6UUjlCA10ppXKEBrpSSuUIDXSllMoRGuhKKZUjNNCVUipHaKArpVSO0EBXSqkcoYGulFI5QgNdKaVyhAa6UkrlCA10pZTKERroSimVIzTQlVIqR2igK6VUjuhVoIvIuSLyjohsFJGbDjD930RkZc/PBhFp6/NKlVJKHZJzuBlExAbuAs4B6oDlIrLYGLN29zzGmBv3mv864Lh+qFUppdQh9OYIfSaw0RizyRiTABYCFx1i/suA3/ZFcUoppXqvN4FeA2zba7iuZ9x+RGQ4MBJ4/qOXppRS6kj09UnRS4HHjDHugSaKyDUiskJEVjQ2NvbxqpVS6tjWm0DfDgzda3hIz7gDuZRDNLcYY+41xswwxsyoqKjofZVKKaUOqzeBvhwYKyIjRcRPOrQXf3gmEZkAlACv9m2JSimleuOwgW6MSQHXAs8A64BHjTFrROQOEblwr1kvBRYaY0z/lKqUUupQDnvZIoAx5ingqQ+N+96Hhm/vu7KUUkodqV4FulIq9yWTSerq6ojFYpkuRQHBYJAhQ4bg8/l6/RwNdKUUAHV1dRQUFDBixAhEJNPlHNOMMTQ3N1NXV8fIkSN7/Tzty0UpBUAsFqOsrEzDfAAQEcrKyo74vyUNdKXUHhrmA8fR7AsNdKWUyhEa6EqpASMcDme6hKymga6UUjlCr3JRSu3nn/64hrU7Ovp0mZOqC/n+BZN7Na8xhm9/+9v86U9/QkS47bbbmDt3Ljt37mTu3Ll0dHSQSqW4++67OfXUU7nqqqtYsWIFIsKVV17JjTfeePiV5CANdKXUgPP73/+elStX8tZbb9HU1MSJJ57IGWecwcMPP8ynPvUpbr31VlzXJRqNsnLlSrZv387bb78NQFtbW2aLzyANdKXUfnp7JN1fXn75ZS677DJs26ayspIzzzyT5cuXc+KJJ3LllVeSTCa5+OKLmT59OqNGjWLTpk1cd911fPrTn+aTn/xkRmvPJG1DV0pljTPOOIOlS5dSU1PDFVdcwYIFCygpKeGtt95i1qxZ3HPPPcyfPz/TZWaMBrpSasA5/fTTeeSRR3Bdl8bGRpYuXcrMmTPZsmULlZWVXH311cyfP5833niDpqYmPM/jkksu4c477+SNN97IdPkZo00uSqkB5zOf+Qyvvvoq06ZNQ0T4yU9+QlVVFQ888AA//elP8fl8hMNhFixYwPbt25k3bx6e5wHw4x//OMPVZ45kqrfbGTNmmBUrVmRk3Uqp/a1bt46JEydmugy1lwPtExF53Rgz40Dza5OLUkrlCA10pZTKERroSimVIzTQlVIqR2igK6VUjtBAV0qpHKGBrpRSOUIDXSl1zEmlUpkuoV/onaJKqf396SbYtbpvl1lVC+f982Fnu/jii9m2bRuxWIwbbriBa665hqeffppbbrkF13UpLy/nL3/5C5FIhOuuu25Pt7nf//73ueSSSwiHw0QiEQAee+wxnnjiCe6//36uuOIKgsEgb775JqeddhqXXnopN9xwA7FYjFAoxH333cf48eNxXZfvfOc7PP3001iWxdVXX83kyZP5xS9+wR/+8AcAnn32WX75y1+yaNGivn2NPiINdKXUgPKb3/yG0tJSuru7OfHEE7nooou4+uqrWbp0KSNHjqSlpQWAH/zgBxQVFbF6dfqDp7W19bDLrqur45VXXsG2bTo6OnjppZdwHIfnnnuOW265hccff5x7772XzZs3s3LlShzHoaWlhZKSEr72ta/R2NhIRUUF9913H1deeWW/vg5HQwNdKbW/XhxJ95df/OIXe458t23bxr333ssZZ5zByJEjASgtLQXgueeeY+HChXueV1JScthlz5kzB9u2AWhvb+fLX/4y7777LiJCMpncs9yvfOUrOI6zz/q++MUv8j//8z/MmzePV199lQULFvTRFvcdDXSl1IDxwgsv8Nxzz/Hqq6+Sl5fHrFmzmD59OuvXr+/1MkRkz+NYLLbPtPz8/D2Pv/vd73LWWWexaNEiNm/ezKxZsw653Hnz5nHBBRcQDAaZM2fOnsAfSPSkqFJqwGhvb6ekpIS8vDzWr1/PsmXLiMViLF26lPfffx9gT5PLOeecw1133bXnububXCorK1m3bh2e5x2yjbu9vZ2amhoA7r///j3jzznnHH71q1/tOXG6e33V1dVUV1dz5513Mm/evL7b6D6kga6UGjDOPfdcUqkUEydO5KabbuLkk0+moqKCe++9l89+9rNMmzaNuXPnAnDbbbfR2trKlClTmDZtGkuWLAHgn//5n5k9ezannnoqgwcPPui6vv3tb3PzzTdz3HHH7XPVy/z58xk2bBhTp05l2rRpPPzww3umXX755QwdOnTA9kqp3ecqpQDtPrc3rr32Wo477jiuuuqqj2V9/dJ9roicKyLviMhGEbnpIPN8TkTWisgaEXn4QPMopVS2OuGEE1i1ahVf+MIXMl3KQR22VV9EbOAu4BygDlguIouNMWv3mmcscDNwmjGmVUQG9VfBSimVCa+//nqmSzis3hyhzwQ2GmM2GWMSwELgog/NczVwlzGmFcAY09C3ZSqllDqc3gR6DbBtr+G6nnF7GweME5G/isgyETn3QAsSkWtEZIWIrGhsbDy6ipVSSh1QX13l4gBjgVnAZcB/i0jxh2cyxtxrjJlhjJlRUVHRR6tWSikFvQv07cDQvYaH9IzbWx2w2BiTNMa8D2wgHfBKKaU+Jr0J9OXAWBEZKSJ+4FJg8Yfm+QPpo3NEpJx0E8ymvitTKaX2FQ6HDzpt8+bNTJky5WOsZmA4bKAbY1LAtcAzwDrgUWPMGhG5Q0Qu7JntGaBZRNYCS4BvGWOa+6topZRS++tVZwTGmKeApz407nt7PTbAN3p+lFJZ7l/+9i+sb+l9/ym9MaF0At+Z+Z2DTr/pppsYOnQo//AP/wDA7bffjuM4LFmyhNbWVpLJJHfeeScXXfThi+wOLRaL8dWvfpUVK1bgOA4///nPOeuss1izZg3z5s0jkUjgeR6PP/441dXVfO5zn6Ourg7Xdfnud7+7587UbDDwepdRSh2T5s6dy9e//vU9gf7oo4/yzDPPcP3111NYWEhTUxMnn3wyF1544T4dcB3OXXfdhYiwevVq1q9fzyc/+Uk2bNjAPffcww033MDll19OIpHAdV2eeuopqqurefLJJ4F0fy/ZRANdKbWfQx1J95fjjjuOhoYGduzYQWNjIyUlJVRVVXHjjTeydOlSLMti+/bt1NfXU1VV1evlvvzyy1x33XUATJgwgeHDh7NhwwZOOeUUfvjDH1JXV8dnP/tZxo4dS21tLd/85jf5zne+w+zZszn99NP7a3P7hXbOpZQaMObMmcNjjz3GI488wty5c3nooYdobGzk9ddfZ+XKlVRWVu7XJe7R+vznP8/ixYsJhUKcf/75PP/884wbN4433niD2tpabrvtNu64444+WdfHRY/QlVIDxty5c7n66qtpamrixRdf5NFHH2XQoEH4fD6WLFnCli1bjniZp59+Og899BBnn302GzZsYOvWrYwfP55NmzYxatQorr/+erZu3cqqVauYMGECpaWlfOELX6C4uJhf//rX/bCV/UcDXSk1YEyePJnOzk5qamoYPHgwl19+ORdccAG1tbXMmDGDCRMmHPEyv/a1r/HVr36V2tpaHMfh/vvvJxAI8Oijj/Lggw/i8/moqqrilltuYfny5XzrW9/Csix8Ph933313P2xl/9Huc5VSgHafOxD1S/e5SimlBj5tclFKZa3Vq1fzxS9+cZ9xgUCA1157LUMVZZYGulIqa9XW1rJy5cpMlzFgaJOLUkrlCA10pZTKERroSimVIzTQlVIqR2igK6Wy0qH6Qz9WaaArpdRHkEqlMl3CHnrZolJqP7t+9CPi6/q2P/TAxAlU3XLLQaf3ZX/okUiEiy666IDPW7BgAT/72c8QEaZOncqDDz5IfX09X/nKV9i0Kf1Fa3fffTfV1dXMnj2bt99+G4Cf/exnRCIRbr/9dmbNmsX06dN5+eWXueyyyxg3bhx33nkniUSCsrIyHnroISorK4lEIlx33XWsWLECEeH73/8+7e3trFq1in//938H4L//+79Zu3Yt//Zv//ZRXl5AA10pNUD0ZX/owWCQRYsW7fe8tWvXcuedd/LKK69QXl5OS0sLANdffz1nnnkmixYtwnVdIpEIra2th1xHIpFgd/clra2tLFu2DBHh17/+NT/5yU/413/9V37wgx9QVFTE6tWr98zn8/n44Q9/yE9/+lN8Ph/33Xcfv/rVrz7qywdooCulDuBQR9L9pS/7QzfGcMstt+z3vOeff545c+ZQXl4OQGlpKQDPP/88CxYsAMC2bYqKig4b6Ht/k1FdXR1z585l586dJBIJRo4cCcBzzz3HwoUL98xXUlICwNlnn80TTzzBxIkTSSaT1NbWHuGrdWAa6EqpAWN3f+i7du3arz90n8/HiBEjetUf+tE+b2+O4+B53p7hDz8/Pz9/z+PrrruOb3zjG1x44YW88MIL3H777Ydc9vz58/nRj37EhAkTmDdv3hHVdSh6UlQpNWDMnTuXhQsX8thjjzFnzhza29uPqj/0gz3v7LPP5ne/+x3NzenvsN/d5PKJT3xiT1e5ruvS3t5OZWUlDQ0NNDc3E4/HeeKJJw65vpqaGgAeeOCBPePPOecc7rrrrj3Du4/6TzrpJLZt28bDDz/MZZdd1tuX57A00JVSA8aB+kNfsWIFtbW1LFiwoNf9oR/seZMnT+bWW2/lzDPPZNq0aXzjG+nvtf+P//gPlixZQm1tLSeccAJr167F5/Pxve99j5kzZ3LOOeccct233347c+bM4YQTTtjTnANw22230draypQpU5g2bRpLlizZM+1zn/scp5122p5mmL6g/aErpQDtD/3jNnv2bG688UY+8YlPHHQe7Q9dKaUGsLa2NsaNG0coFDpkmB8NPSmqlMpa2dgfenFxMRs2bOiXZWugK6X2MMYc9hrvgSSX+0M/muZwbXJRSgHpm3Gam5uPKkhU3zLG0NzcTDAYPKLn6RG6UgqAIUOGUFdXR2NjY6ZLUaQ/YIcMGXJEz9FAV0oB4PP59tzhqLJTr5pcRORcEXlHRDaKyE0HmH6FiDSKyMqen/l9X6pSSqlDOewRuojYwF3AOUAdsFxEFhtj1n5o1keMMdf2Q41KKaV6oTdH6DOBjcaYTcaYBLAQOHz/lUoppT5WvQn0GmDbXsN1PeM+7BIRWSUij4nI0AMtSESuEZEVIrJCT7wopVTf6qvLFv8IjDDGTAWeBR440EzGmHuNMTOMMTMqKir6aNVKKaWgd4G+Hdj7iHtIz7g9jDHNxph4z+CvgRP6pjyllFK91ZtAXw6MFZGRIuIHLgUW7z2DiAzea/BCYF3flaiUUqo3DnuVizEmJSLXAs8ANvAbY8waEbkDWGGMWQxcLyIXAimgBbiiH2tWSil1ANp9rlJKZRHtPlcppY4BWRfoxhjqO47suwGVUupYkHWB/l/Pb+SUH/+FWNLNdClKKTWgZF2gjxkUxjPwbn0k06UopdSAknWBPr6qAID1uzoyXIlSSg0sWRfow8vyCfos1u/qzHQpSik1oGRdoNuWMK6ygHc00JVSah9ZF+gA4ysL9AhdKaU+JDsDvaqApkicpkj88DMrpdQxIisDfeLgQgBtdlFKqb1kZaB/cKWLBrpSSu2WlYFeHg5QHvazfqdeuqiUUrtlZaDv6trFhKpC3qnXI3SllNot6wL93lX38unff5pRg2w21HfiepnpLVIppQaarAv0mVUzSXgJ3Ly3iSU9trZEM12SUkoNCFkX6NMqplETrmFL7GUAbUdXSqkeWRfoIsK5I87l7ZYVWE6ElXVtmS5JKaUGhKwLdIDzRp6Ha1wmj93MI8u30RVPZbokpZTKuKwM9HEl4xhdNBp/0Sraokkeem1LpktSSqmMy8pAFxHOG3keG9pXcdJY4d6l7+sXXiiljnlZGeiQbnYBmDBmI02ROI8s35bhipRSKrOyNtCHFQ5jZtVMXqr/AzNGFHDPi+/pUbpS6piWtYEOML92Po3djcyY8h4722P8zzJtS1dKHbuyOtBPHnwyU8qm8GL9o5w+rpT/fH4j7dFkpstSSqmMyOpAFxHmT51PXaSO06dtpyOW5Jcvbsx0WUoplRFZHegAZw09i9FFo/lT3UNcPG0w9/11MzvaujNdllJKfeyyPtAtsbiq9io2tm3k1Kn1YOAXf3k302UppdTHLusDHdKXMA4tGMrjmx5g7olDeOz1OupatdMupdSxpVeBLiLnisg7IrJRRG46xHyXiIgRkRl9V+LhOZbD/Nr5rGlew4mTGrFE+OUL732cJSilVMYdNtBFxAbuAs4DJgGXicikA8xXANwAvNbXRfbGBaMuoCq/it9tvI85M2r43YptbNe2dKXUMaQ3R+gzgY3GmE3GmASwELjoAPP9APgXINaH9fWaz/Zx5ZQrWdm4ktOmtANwjx6lK6WOIb0J9Bpg7/vq63rG7SEixwNDjTFPHmpBInKNiKwQkRWNjY1HXOzhfHbsZxkUGsQD7/wXlxxfwyPLt7FNvwBDKXWM+MgnRUXEAn4OfPNw8xpj7jXGzDDGzKioqPioq95PwA7wjyf+I2ub1zJ69NtYFvzL0+v7fD1KKTUQ9SbQtwND9xoe0jNutwJgCvCCiGwGTgYWf9wnRnc7d8S5zKyayf3rfsmXTqvgiVU7eX1LayZKUUqpj1VvAn05MFZERoqIH7gUWLx7ojGm3RhTbowZYYwZASwDLjTGrOiXig9DRLh55s1Ek1G68hdTURDgzifXYox+mbRSKrcdNtCNMSngWuAZYB3wqDFmjYjcISIX9neBR2NMyRgun3g5izct4vOnw5tb21j81o5Ml6WUUv1KMnXkOmPGDLNiRf8dxEcSEWYvmk1NuIb2Tf+XXe1x/nzjmZTm+/ttnUop1d9E5HVjzAGbtHPiTtEDCfvD3HjCjaxqWsXsU3fSFk1yxx/XZLospZTqNzkb6AAXjL6A2vJaHnnvHq45s4Y/rNzBc2vrM12WUkr1i5wOdEssbp55M03dTXSFFzGhqoBbFq2moSMj9z4ppVS/yulAB6itqGXelHn8fuPjzD5tK5F4iqsffF2/rk4plXNyPtABbjjuBk4ZfAq/Wf9zvv7pAG9ta+Nbj63SSxmVUjnlmAh027L56Zk/ZVDeIH675Q6uOMvhj2/t4PuL15ByvUyXp5RSfeKYCHSAokARd33iLhzL4cnG2/jUiQ0seHULVz6wgo6Yfg+pUir7HTOBDjC6eDS//fRvGV86nlciP+fc01fyysYGLv6vv/L6lpZMl6eUUh/JMRXoAOWhcn7zqd9w8ZiL+WvTQk446XG63Q7+zz2vcvviNXTq0bpSKkvl7J2ih2OM4ffv/p4fvfYj8n1hKvg73lgzjgK7ii+dMoJ5p42gLBzIWH1KKXUgh7pT9JgN9N3WNq/l7pV3s3T7UjzjUcwUdm49CSs+jk/XVvP5k4YxY3gJIpLpUpVSSgO9NxqiDSx6dxEL31lIU3cTYauaztZRxDpGMjgwlfOnDOeTk6qorSnC7xxzLVVKqQFCA/0IJNwET256kifff5KVDSuJu3HE+EhFxpFon4YVrWVSdQknjihh5sgypg8tpjzs1yN4pdTHQgP9KCXcBCsbVvLc1uf48+ZnaY41kW9VkB87m23bJpFIpNvYA45FdXGIMYPCTK4uZHxlAdXFIaqLQ5Tl+7EsDXulVN/QQO8DnvF4cduL3L/mft5oeANbHMYXTafEmkA0btHe7dLYDg3tgkmF8RIVGDcfv2NRXRSkujjEsNI8hpbmMaQkxJCSEIOLQpSF/QQcO9Obp5TKEhrofWxN0xr+vOXPPL/1eTZ3bD7ofEGrAJ+E8TyHZEpIenFck8K4IbxkEcYtwLghAlYeISefPCefsFNMuX8UJcFiCkIG17cV7A7ynTIKnHKqw4MYXBimMOTDEgHxaIk3UB/djiFJbeUYxpQMx7b0Q0KpXKSB3k+MMcTcGK7nkvJSRFNROhOd1Efr2dy+mc0dm4kkIul5jEvADiDYNERaqI820JZoIeZGMOzf/YC4xXhWByL7T/NSeWD8iBUHK77fPMZYiLExGMBCTADLBLG9UgIMIiB5GLsdz4rgUIjtDgIvgGe141nt2LaHzwZLbDw3iHEDBHwWIb+QpJ2m+BY6UrvwSYg8uxTHcoh77cS8CHlOIYVOOeXBIYwtmMrwwjFs6FzOaw1/pjPZzvjiWkYXTKE0MJiwU4ptWaRoIykRqkNDGRYeS1GwgMKgj3DQQYCUl6It3klTdxuReJRhhUMpCYVxLHin9R3ebnqboeFhjCqcSMiXR57PxrEtXM+lJdaCz/JRHCw+5L70TPo1tGT/E97RZJTG7kaGhIfs80FpjCHhJYgmoziWQ9gX3u9cimc82uPtFAWKDrjsQ9m9/ICtl8+qD2igD2DGGKKpKF3JLrqSXezs2sna5rW82/ouNeEaJpbWUugMojnWQH20nh2d9eyMNNKVjBKw8vBbeRT7B1EWqMbzHN5v38zO6DZcL4UlFh4uCbebmNdF1G0gaurxiGObIsQL41kduFYbAGIcLFOI8Rw8TzC4WHYMY8XBpD8ojBvCS1RhpSpA4hi7A0MK44Yxbh5iRxFfG3ZgF2J/0E1xKjoCkyjFztuM5T/0XbnGDQEm/WMlD/CBJZhEGdgxLCey73g3DAZEDNhd6d+Qri1VBm4enhvAeEGMG0KwsYLbkeAWIIWkyhG3FBGDZSfw7FZcK12vbfIIeeOw8JOw6ohLPYYPeu0UbBwKcEwhjikkRZSYbMdI+sS631TgoxifFcInQTA+PNfBTymFMoZ8q5Iu2UQn6+g0W+gydbhECTOOMplBvlRirASWlcJng21Bt9dMa3I7cdNOqTOGwf4piHg0JzfR5TWRxxBC3kgCUkHIysO1ouxMvspOdxkJWgGDI36q/FMYGjyBIqcGW/x4JklT8j2ak+9hESBsDSVkqpFUCfGkg/ibiPneIsoOiqwR5JkxIAm6pY6EaSXPLiMk5cTcCG2p7aRMjOF50xldMA1bAiRSHkk3SUNiA9vib9DtNZM0EVImjufZuK6Dz3II+fzYtktrvJ7WRAMAjoQIWgWU+ocwKDiM6tBohuaPJ+wrIu7G6Ey24JoUgo0tDiEnn3xfHkiCJO0kvCjxlEc85RJNxommYiTcbly6cCVKoa+Cct8oivyV+Jw4WDESboJIIn3TYUV+ARV5BSRdob3b4Lo25flBysIBUp4hGk/RnXTpiEdojTdTFS5lZGkFQcdmfdMWVjeu4cwR0zlp2LijSAwNdLWX3ft77yPJaDJKd6qbkmDJIY8iU65HPOUR8tn7nOhNpDw6Ykk6utNveNsSkp7Luy0b2NC2geF5k8m3q3A9D8ey6Pba6Uo10+W2knRdHFNMKhWgJVFHfXwjnclWkq6QShls8eOIH78dIuwrJOgEaIxtoz72PoJDtX86Zc544lJPa2ojXW4LSc/D9SBkFRGyS3C9FK3J7XS6u0iZKC4xkiZK3IvgkaLIHkqpnQ7qiLeLqNeEGAfBj2OK8LmDMakCYvYmovZ6DB5+dwhWqhLLy8cYHyIunhXBkwjG7sSzOrAJks9QQlJBzLTQbepJ0kGKGB4xEBckgScf6p/f+PClhhIwNTiE6LJXk7R3HnS/SKoEy+TjOjtg7w8/LwjWgfv+t5NDsJLVpDxw6UJCGxE7vv/7xXNA3D0fjADiBTE9y/VSeVhOdN/nGNlnfmMEjI1YKYznw6QKwQjidCF2d/pAIVmMcUMYz4+Ii9hJDC6Ch8HCJEvwksWAIFYcsSNYgQYsX/sH63H9iJ046OvU34yxwDgYz9ezDR+89sb1A9aecWdVzOcX599wVOvRQFfqIFJeCsdyMlpDQ7SBVY2r2Na5jSnlU5hWMQ2/ve93325u30xbvI2QEyJgB7DFBoGyYBl5vjwg/T26bza8id/2M6lsEmFfmF1du1jdtJrG7kYiiQiWWJw19CzGlIzZZ/lJN8nKxpU0RBuIpWKICBNKJzC2ZCwpL8Wmtk1sat9EfbSe+q56hhUO48yasyhwKuhMNbKmZTV5Th6ji8ZR4CulPdFMQ/cuigOFDCschucZXtnxN16qe4n2RBvgkefL4+TBpzCz6hRsEyIST5HyDBUFAQoCDinP0NgZpzWawLEsbAuCPptwwMHvWCRThpbudta3rmd9yxoauxsoDZZTFqzAZzl4eCTcOF3JLiLJLnwSImQVEbTzCTg2Psci7AsSDgQJOSH8UoCYEI3d29kS2UBLvBGf5GOTR9AOEPI5GDyao120xSLYlkfAZ/BI0ZVI0hVP4JHESAKfZTMor4ryUBn1Xa1s7agj4SYYUzye2vLJnDp0EuXhgqN6v2igK6VUjjgmvyRaKaWONRroSimVIzTQlVIqR2igK6VUjtBAV0qpHKGBrpRSOUIDXSmlcoQGulJK5YiM3VgkIo3AlqN8ejnQ1IflZIpux8Ci2zGw6HYc2HBjTMWBJmQs0D8KEVlxsDulsolux8Ci2zGw6HYcOW1yUUqpHKGBrpRSOSJbA/3eTBfQR3Q7BhbdjoFFt+MIZWUbulJKqf1l6xG6UkqpD9FAV0qpHJF1gS4i54rIOyKyUURuynQ9vSUiQ0VkiYisFZE1InJDz/hSEXlWRN7t+V2S6VoPR0RsEXlTRJ7oGR4pIq/17JNHRMR/uGVkmogUi8hjIrJeRNaJyClZui9u7Hk/vS0ivxWRYDbsDxH5jYg0iMjbe4074Osvab/o2Z5VInJ85irf10G246c976tVIrJIRIr3mnZzz3a8IyKf6ut6sirQRcQG7gLOAyYBl4nIpMxW1Wsp4JvGmEnAycA/9NR+E/AXY8xY4C89wwPdDcC6vYb/Bfg3Y8wYoBW4KiNVHZn/AJ42xkwAppHenqzaFyJSA1wPzDDGTAFs4FKyY3/cD5z7oXEHe/3PA8b2/FwD3P0x1dgb97P/djwLTDHGTAU2ADcD9Py9XwpM7nnOL3syrc9kVaADM4GNxphNxpgEsBC4KMM19YoxZqcx5o2ex52kA6SGdP0P9Mz2AHBxRgrsJREZAnwa+HXPsABnA4/1zJIN21AEnAH8PwBjTMIY00aW7YseDhASEQfIA3aSBfvDGLMUaPnQ6IO9/hcBC0zaMqBYRAZ/LIUexoG2wxjzZ2NMqmdwGTCk5/FFwEJjTNwY8z6wkXSm9ZlsC/QaYNtew3U947KKiIwAjgNeAyqNMbu/0n0XUJmpunrp34FvA7u/Xr4MaNvrDZwN+2Qk0Ajc19N09GsRySfL9oUxZjvwM2Ar6SBvB14n+/bHbgd7/bP57/5K4E89j/t9O7It0LOeiISBx4GvG2M69p5m0teQDtjrSEVkNtBgjHk907V8RA5wPHC3MeY4oIsPNa8M9H0B0NPGfBHpD6hqIJ/9//3PStnw+h+OiNxKuqn1oY9rndkW6NuBoXsND+kZlxVExEc6zB8yxvy+Z3T97n8fe343ZKq+XjgNuFBENpNu7jqbdFt0cc+//JAd+6QOqDPGvNYz/BjpgM+mfQHw98D7xphGY0wS+D3pfZRt+2O3g73+Wfd3LyJXALOBy80HN/v0+3ZkW6AvB8b2nMX3kz7BsDjDNfVKT1vz/wPWGWN+vtekxcCXex5/Gfjfj7u23jLG3GyMGWKMGUH6tX/eGHM5sAT4Pz2zDehtADDG7AK2icj4nlGfANaSRfuix1bgZBHJ63l/7d6OrNofeznY678Y+FLP1S4nA+17Nc0MOCJyLulmyQuNMdG9Ji0GLhWRgIiMJH2S9299unJjTFb9AOeTPnP8HnBrpus5grr/jvS/kKuAlT0/55Nug/4L8C7wHFCa6Vp7uT2zgCd6Ho/qeWNuBH4HBDJdXy/qnw6s6NkffwBKsnFfAP8ErAfeBh4EAtmwP4Dfkm73T5L+j+mqg73+gJC+uu09YDXpq3oyvg2H2I6NpNvKd/+d37PX/Lf2bMc7wHl9XY/e+q+UUjki25pclFJKHYQGulJK5QgNdKWUyhEa6EoplSM00JVSKkdooCulVI7QQFdKqRzx/wFSCaHRVbgdmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26165951",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5a36c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yestimated=d1.predict(xtest)\n",
    "yestimated=(yestimated>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "062749a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yestimated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e803d64",
   "metadata": {},
   "source": [
    "## Performance metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9890c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[1521   64]\n",
      " [ 212  203]]\n",
      "accuracy= 0.862\n",
      "precision= 0.7602996254681648\n",
      "recall= 0.4891566265060241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score, recall_score\n",
    "cm=confusion_matrix(ytest, yestimated) \n",
    "print('confusion matrix')\n",
    "print(cm)\n",
    "print('accuracy=', accuracy_score(ytest,yestimated))\n",
    "print('precision=', precision_score(ytest,yestimated))\n",
    "print('recall=', recall_score(ytest, yestimated))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c834a3ee",
   "metadata": {},
   "source": [
    "## Model using 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "794ec082",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a1c06f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first hidden layer\n",
    "d2.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
    "#2nd hidden layer\n",
    "d2.add(tf.keras.layers.Dense(units=8,activation='relu'))\n",
    "#output layer\n",
    "d2.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b2ce072",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf33019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5169 - accuracy: 0.7822 - val_loss: 0.4442 - val_accuracy: 0.8085\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.8111 - val_loss: 0.4170 - val_accuracy: 0.8165\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8159 - val_loss: 0.4063 - val_accuracy: 0.8235\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4140 - accuracy: 0.8225 - val_loss: 0.3975 - val_accuracy: 0.8285\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8266 - val_loss: 0.3910 - val_accuracy: 0.8310\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8282 - val_loss: 0.3851 - val_accuracy: 0.8345\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8306 - val_loss: 0.3837 - val_accuracy: 0.8375\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8320 - val_loss: 0.3794 - val_accuracy: 0.8410\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8321 - val_loss: 0.3773 - val_accuracy: 0.8390\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8366 - val_loss: 0.3762 - val_accuracy: 0.8405\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8378 - val_loss: 0.3736 - val_accuracy: 0.8425\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8415 - val_loss: 0.3704 - val_accuracy: 0.8480\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8443 - val_loss: 0.3677 - val_accuracy: 0.8490\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8460 - val_loss: 0.3674 - val_accuracy: 0.8470\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8461 - val_loss: 0.3640 - val_accuracy: 0.8485\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8489 - val_loss: 0.3617 - val_accuracy: 0.8485\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8487 - val_loss: 0.3606 - val_accuracy: 0.8495\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8536 - val_loss: 0.3562 - val_accuracy: 0.8525\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8528 - val_loss: 0.3546 - val_accuracy: 0.8520\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8546 - val_loss: 0.3549 - val_accuracy: 0.8515\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8554 - val_loss: 0.3522 - val_accuracy: 0.8545\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8546 - val_loss: 0.3552 - val_accuracy: 0.8525\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8559 - val_loss: 0.3495 - val_accuracy: 0.8545\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8565 - val_loss: 0.3485 - val_accuracy: 0.8560\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8577 - val_loss: 0.3496 - val_accuracy: 0.8530\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8591 - val_loss: 0.3463 - val_accuracy: 0.8575\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8571 - val_loss: 0.3471 - val_accuracy: 0.8580\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8579 - val_loss: 0.3471 - val_accuracy: 0.8590\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8602 - val_loss: 0.3447 - val_accuracy: 0.8550\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8597 - val_loss: 0.3422 - val_accuracy: 0.8610\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8595 - val_loss: 0.3432 - val_accuracy: 0.8635\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3391 - accuracy: 0.8589 - val_loss: 0.3446 - val_accuracy: 0.8625\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8585 - val_loss: 0.3443 - val_accuracy: 0.8600\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8602 - val_loss: 0.3404 - val_accuracy: 0.8590\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8599 - val_loss: 0.3403 - val_accuracy: 0.8645\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3374 - accuracy: 0.8599 - val_loss: 0.3397 - val_accuracy: 0.8610\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8599 - val_loss: 0.3403 - val_accuracy: 0.8585\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8589 - val_loss: 0.3389 - val_accuracy: 0.8600\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8622 - val_loss: 0.3373 - val_accuracy: 0.8630\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8604 - val_loss: 0.3409 - val_accuracy: 0.8605\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3337 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8611 - val_loss: 0.3378 - val_accuracy: 0.8625\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8609 - val_loss: 0.3373 - val_accuracy: 0.8610\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8619 - val_loss: 0.3399 - val_accuracy: 0.8605\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3333 - accuracy: 0.8616 - val_loss: 0.3373 - val_accuracy: 0.8580\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8610 - val_loss: 0.3402 - val_accuracy: 0.8650\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8618 - val_loss: 0.3363 - val_accuracy: 0.8630\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8625 - val_loss: 0.3367 - val_accuracy: 0.8630\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8616 - val_loss: 0.3379 - val_accuracy: 0.8615\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8634 - val_loss: 0.3371 - val_accuracy: 0.8610\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8612 - val_loss: 0.3376 - val_accuracy: 0.8625\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8612 - val_loss: 0.3396 - val_accuracy: 0.8640\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8624 - val_loss: 0.3391 - val_accuracy: 0.8620\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8637 - val_loss: 0.3372 - val_accuracy: 0.8650\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8640 - val_loss: 0.3362 - val_accuracy: 0.8630\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8634 - val_loss: 0.3385 - val_accuracy: 0.8610\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8640 - val_loss: 0.3360 - val_accuracy: 0.8650\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8612 - val_loss: 0.3350 - val_accuracy: 0.8645\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8629 - val_loss: 0.3360 - val_accuracy: 0.8640\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3282 - accuracy: 0.8645 - val_loss: 0.3385 - val_accuracy: 0.8600\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8644 - val_loss: 0.3358 - val_accuracy: 0.8665\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8636 - val_loss: 0.3365 - val_accuracy: 0.8605\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3275 - accuracy: 0.8635 - val_loss: 0.3353 - val_accuracy: 0.8635\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8627 - val_loss: 0.3345 - val_accuracy: 0.8685\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8630 - val_loss: 0.3348 - val_accuracy: 0.8645\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8636 - val_loss: 0.3363 - val_accuracy: 0.8625\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8651 - val_loss: 0.3362 - val_accuracy: 0.8615\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8641 - val_loss: 0.3376 - val_accuracy: 0.8625\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8618 - val_loss: 0.3346 - val_accuracy: 0.8650\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8645 - val_loss: 0.3396 - val_accuracy: 0.8630\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8651 - val_loss: 0.3372 - val_accuracy: 0.8615\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8648 - val_loss: 0.3397 - val_accuracy: 0.8590\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8645 - val_loss: 0.3356 - val_accuracy: 0.8665\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8634 - val_loss: 0.3358 - val_accuracy: 0.8635\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8627 - val_loss: 0.3351 - val_accuracy: 0.8640\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8639 - val_loss: 0.3393 - val_accuracy: 0.8575\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3255 - accuracy: 0.8619 - val_loss: 0.3355 - val_accuracy: 0.8620\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8630 - val_loss: 0.3373 - val_accuracy: 0.8605\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8644 - val_loss: 0.3390 - val_accuracy: 0.8635\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8635 - val_loss: 0.3377 - val_accuracy: 0.8620\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8655 - val_loss: 0.3367 - val_accuracy: 0.8665\n",
      "Epoch 81/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8630 - val_loss: 0.3381 - val_accuracy: 0.8585\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8633 - val_loss: 0.3353 - val_accuracy: 0.8640\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8630 - val_loss: 0.3354 - val_accuracy: 0.8675\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8637 - val_loss: 0.3356 - val_accuracy: 0.8650\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8640 - val_loss: 0.3368 - val_accuracy: 0.8630\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8631 - val_loss: 0.3368 - val_accuracy: 0.8655\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8646 - val_loss: 0.3385 - val_accuracy: 0.8615\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8645 - val_loss: 0.3374 - val_accuracy: 0.8655\n",
      "Epoch 00088: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e603137eb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
    "d2.fit(xtrain, ytrain, epochs=500, validation_data=(xtest,ytest),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f93e9509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.516883</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.444181</td>\n",
       "      <td>0.8085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.439280</td>\n",
       "      <td>0.811125</td>\n",
       "      <td>0.417045</td>\n",
       "      <td>0.8165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.423926</td>\n",
       "      <td>0.815875</td>\n",
       "      <td>0.406339</td>\n",
       "      <td>0.8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.413985</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>0.397513</td>\n",
       "      <td>0.8285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.405835</td>\n",
       "      <td>0.826625</td>\n",
       "      <td>0.391003</td>\n",
       "      <td>0.8310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.325233</td>\n",
       "      <td>0.863750</td>\n",
       "      <td>0.335553</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.324664</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.336768</td>\n",
       "      <td>0.8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.325147</td>\n",
       "      <td>0.863125</td>\n",
       "      <td>0.336823</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.324430</td>\n",
       "      <td>0.864625</td>\n",
       "      <td>0.338474</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.323964</td>\n",
       "      <td>0.864500</td>\n",
       "      <td>0.337359</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   0.516883  0.782250  0.444181        0.8085\n",
       "1   0.439280  0.811125  0.417045        0.8165\n",
       "2   0.423926  0.815875  0.406339        0.8235\n",
       "3   0.413985  0.822500  0.397513        0.8285\n",
       "4   0.405835  0.826625  0.391003        0.8310\n",
       "..       ...       ...       ...           ...\n",
       "83  0.325233  0.863750  0.335553        0.8650\n",
       "84  0.324664  0.864000  0.336768        0.8630\n",
       "85  0.325147  0.863125  0.336823        0.8655\n",
       "86  0.324430  0.864625  0.338474        0.8615\n",
       "87  0.323964  0.864500  0.337359        0.8655\n",
       "\n",
       "[88 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses2=pd.DataFrame(d2.history.history)\n",
    "losses2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4a13c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f1d2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "yestimated1=d2.predict(xtest)\n",
    "yestimated1=(yestimated1>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05163456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yestimated1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1eb75ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[1521   64]\n",
      " [ 212  203]]\n",
      "accuracy= 0.862\n",
      "precision= 0.7602996254681648\n",
      "recall= 0.4891566265060241\n"
     ]
    }
   ],
   "source": [
    "cm1=confusion_matrix(ytest, yestimated) \n",
    "print('confusion matrix')\n",
    "print(cm1)\n",
    "print('accuracy=', accuracy_score(ytest,yestimated))\n",
    "print('precision=', precision_score(ytest,yestimated))\n",
    "print('recall=', recall_score(ytest, yestimated))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0c674",
   "metadata": {},
   "source": [
    "## model with 3 hidden layers and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b14d4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54435ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first hidden layer\n",
    "d3.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
    "d3.add(Dropout(0.5))\n",
    "#2nd hidden layer\n",
    "d3.add(tf.keras.layers.Dense(units=8,activation='relu'))\n",
    "d3.add(Dropout(0.5))\n",
    "#3rd hidden layer\n",
    "d3.add(tf.keras.layers.Dense(units=4,activation='relu'))\n",
    "d3.add(Dropout(0.5))\n",
    "#output layer\n",
    "d3.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6553d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a023793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6499 - accuracy: 0.7318 - val_loss: 0.5366 - val_accuracy: 0.7925\n",
      "Epoch 2/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7844 - val_loss: 0.5062 - val_accuracy: 0.7925\n",
      "Epoch 3/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7958 - val_loss: 0.4944 - val_accuracy: 0.7925\n",
      "Epoch 4/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7971 - val_loss: 0.4895 - val_accuracy: 0.7925\n",
      "Epoch 5/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7977 - val_loss: 0.4842 - val_accuracy: 0.7925\n",
      "Epoch 6/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7976 - val_loss: 0.4785 - val_accuracy: 0.7925\n",
      "Epoch 7/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4952 - accuracy: 0.7980 - val_loss: 0.4700 - val_accuracy: 0.7925\n",
      "Epoch 8/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.7991 - val_loss: 0.4660 - val_accuracy: 0.7925\n",
      "Epoch 9/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.7986 - val_loss: 0.4620 - val_accuracy: 0.7925\n",
      "Epoch 10/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7994 - val_loss: 0.4595 - val_accuracy: 0.7925\n",
      "Epoch 11/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7980 - val_loss: 0.4573 - val_accuracy: 0.7925\n",
      "Epoch 12/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4795 - accuracy: 0.7997 - val_loss: 0.4527 - val_accuracy: 0.7925\n",
      "Epoch 13/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4783 - accuracy: 0.8006 - val_loss: 0.4481 - val_accuracy: 0.7925\n",
      "Epoch 14/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4759 - accuracy: 0.8009 - val_loss: 0.4447 - val_accuracy: 0.7925\n",
      "Epoch 15/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4727 - accuracy: 0.8000 - val_loss: 0.4447 - val_accuracy: 0.7925\n",
      "Epoch 16/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4758 - accuracy: 0.7984 - val_loss: 0.4468 - val_accuracy: 0.7925\n",
      "Epoch 17/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4706 - accuracy: 0.7993 - val_loss: 0.4454 - val_accuracy: 0.7925\n",
      "Epoch 18/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4734 - accuracy: 0.8006 - val_loss: 0.4437 - val_accuracy: 0.7925\n",
      "Epoch 19/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4708 - accuracy: 0.7983 - val_loss: 0.4423 - val_accuracy: 0.7925\n",
      "Epoch 20/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4771 - accuracy: 0.7995 - val_loss: 0.4432 - val_accuracy: 0.7925\n",
      "Epoch 21/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4683 - accuracy: 0.8005 - val_loss: 0.4414 - val_accuracy: 0.7925\n",
      "Epoch 22/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4670 - accuracy: 0.8005 - val_loss: 0.4401 - val_accuracy: 0.7925\n",
      "Epoch 23/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.8000 - val_loss: 0.4363 - val_accuracy: 0.7925\n",
      "Epoch 24/400\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4713 - accuracy: 0.8000 - val_loss: 0.4417 - val_accuracy: 0.7925\n",
      "Epoch 25/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4662 - accuracy: 0.8008 - val_loss: 0.4379 - val_accuracy: 0.7925\n",
      "Epoch 26/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4603 - accuracy: 0.7991 - val_loss: 0.4314 - val_accuracy: 0.7925\n",
      "Epoch 27/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.8010 - val_loss: 0.4352 - val_accuracy: 0.7925\n",
      "Epoch 28/400\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4647 - accuracy: 0.8021 - val_loss: 0.4362 - val_accuracy: 0.7925\n",
      "Epoch 29/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4611 - accuracy: 0.8008 - val_loss: 0.4315 - val_accuracy: 0.7925\n",
      "Epoch 30/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4551 - accuracy: 0.8015 - val_loss: 0.4270 - val_accuracy: 0.7925\n",
      "Epoch 31/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.8016 - val_loss: 0.4299 - val_accuracy: 0.7925\n",
      "Epoch 32/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4546 - accuracy: 0.8033 - val_loss: 0.4264 - val_accuracy: 0.7925\n",
      "Epoch 33/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.7976 - val_loss: 0.4275 - val_accuracy: 0.7925\n",
      "Epoch 34/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4558 - accuracy: 0.8035 - val_loss: 0.4232 - val_accuracy: 0.7925\n",
      "Epoch 35/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4571 - accuracy: 0.8027 - val_loss: 0.4205 - val_accuracy: 0.7925\n",
      "Epoch 36/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.8031 - val_loss: 0.4187 - val_accuracy: 0.7925\n",
      "Epoch 37/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4523 - accuracy: 0.8009 - val_loss: 0.4159 - val_accuracy: 0.7925\n",
      "Epoch 38/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8011 - val_loss: 0.4165 - val_accuracy: 0.7925\n",
      "Epoch 39/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4498 - accuracy: 0.8046 - val_loss: 0.4136 - val_accuracy: 0.7925\n",
      "Epoch 40/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4481 - accuracy: 0.8066 - val_loss: 0.4117 - val_accuracy: 0.7930\n",
      "Epoch 41/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4517 - accuracy: 0.8040 - val_loss: 0.4120 - val_accuracy: 0.7935\n",
      "Epoch 42/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4475 - accuracy: 0.8059 - val_loss: 0.4126 - val_accuracy: 0.7950\n",
      "Epoch 43/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4485 - accuracy: 0.8044 - val_loss: 0.4099 - val_accuracy: 0.7950\n",
      "Epoch 44/400\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4479 - accuracy: 0.8043 - val_loss: 0.4088 - val_accuracy: 0.7950\n",
      "Epoch 45/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.8096 - val_loss: 0.4070 - val_accuracy: 0.7980\n",
      "Epoch 46/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4521 - accuracy: 0.8054 - val_loss: 0.4072 - val_accuracy: 0.7975\n",
      "Epoch 47/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8052 - val_loss: 0.4081 - val_accuracy: 0.7975\n",
      "Epoch 48/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4490 - accuracy: 0.8050 - val_loss: 0.4068 - val_accuracy: 0.7965\n",
      "Epoch 49/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8073 - val_loss: 0.4071 - val_accuracy: 0.7975\n",
      "Epoch 50/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4494 - accuracy: 0.8039 - val_loss: 0.4060 - val_accuracy: 0.7975\n",
      "Epoch 51/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.8060 - val_loss: 0.4089 - val_accuracy: 0.7970\n",
      "Epoch 52/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.8036 - val_loss: 0.4103 - val_accuracy: 0.7970\n",
      "Epoch 53/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4458 - accuracy: 0.8054 - val_loss: 0.4075 - val_accuracy: 0.7975\n",
      "Epoch 54/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4545 - accuracy: 0.8023 - val_loss: 0.4123 - val_accuracy: 0.7975\n",
      "Epoch 55/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8083 - val_loss: 0.4040 - val_accuracy: 0.7980\n",
      "Epoch 56/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.8062 - val_loss: 0.4034 - val_accuracy: 0.7985\n",
      "Epoch 57/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.8045 - val_loss: 0.4059 - val_accuracy: 0.7980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8027 - val_loss: 0.4044 - val_accuracy: 0.7975\n",
      "Epoch 59/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8027 - val_loss: 0.4051 - val_accuracy: 0.7970\n",
      "Epoch 60/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4436 - accuracy: 0.8054 - val_loss: 0.4054 - val_accuracy: 0.7970\n",
      "Epoch 61/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8037 - val_loss: 0.4080 - val_accuracy: 0.7970\n",
      "Epoch 62/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8060 - val_loss: 0.4077 - val_accuracy: 0.7980\n",
      "Epoch 63/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8060 - val_loss: 0.4039 - val_accuracy: 0.7980\n",
      "Epoch 64/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.8051 - val_loss: 0.3998 - val_accuracy: 0.7985\n",
      "Epoch 65/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8076 - val_loss: 0.4009 - val_accuracy: 0.7990\n",
      "Epoch 66/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4484 - accuracy: 0.8087 - val_loss: 0.4050 - val_accuracy: 0.8010\n",
      "Epoch 67/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4402 - accuracy: 0.8081 - val_loss: 0.4023 - val_accuracy: 0.8000\n",
      "Epoch 68/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4474 - accuracy: 0.8051 - val_loss: 0.4086 - val_accuracy: 0.7975\n",
      "Epoch 69/400\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.80 - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8077 - val_loss: 0.4081 - val_accuracy: 0.7975\n",
      "Epoch 70/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.8075 - val_loss: 0.4058 - val_accuracy: 0.7990\n",
      "Epoch 71/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4508 - accuracy: 0.8046 - val_loss: 0.4077 - val_accuracy: 0.7990\n",
      "Epoch 72/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8062 - val_loss: 0.4086 - val_accuracy: 0.7990\n",
      "Epoch 73/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8074 - val_loss: 0.4063 - val_accuracy: 0.8005\n",
      "Epoch 74/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.8049 - val_loss: 0.4073 - val_accuracy: 0.7995\n",
      "Epoch 75/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8074 - val_loss: 0.4040 - val_accuracy: 0.7990\n",
      "Epoch 76/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.8079 - val_loss: 0.4033 - val_accuracy: 0.8010\n",
      "Epoch 77/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.8073 - val_loss: 0.4022 - val_accuracy: 0.8010\n",
      "Epoch 78/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8073 - val_loss: 0.4040 - val_accuracy: 0.8010\n",
      "Epoch 79/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8098 - val_loss: 0.4038 - val_accuracy: 0.8010\n",
      "Epoch 80/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8071 - val_loss: 0.4054 - val_accuracy: 0.7985\n",
      "Epoch 81/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4470 - accuracy: 0.8067 - val_loss: 0.4047 - val_accuracy: 0.7990\n",
      "Epoch 82/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.8070 - val_loss: 0.4036 - val_accuracy: 0.7995\n",
      "Epoch 83/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4430 - accuracy: 0.8061 - val_loss: 0.4033 - val_accuracy: 0.7995\n",
      "Epoch 84/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8070 - val_loss: 0.4034 - val_accuracy: 0.7995\n",
      "Epoch 85/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8049 - val_loss: 0.4059 - val_accuracy: 0.7995\n",
      "Epoch 86/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4430 - accuracy: 0.8091 - val_loss: 0.4012 - val_accuracy: 0.8020\n",
      "Epoch 87/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8065 - val_loss: 0.4075 - val_accuracy: 0.7990\n",
      "Epoch 88/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8092 - val_loss: 0.4039 - val_accuracy: 0.8005\n",
      "Epoch 89/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8067 - val_loss: 0.4047 - val_accuracy: 0.8020\n",
      "Epoch 90/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8083 - val_loss: 0.4033 - val_accuracy: 0.8015\n",
      "Epoch 91/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8040 - val_loss: 0.4059 - val_accuracy: 0.8015\n",
      "Epoch 92/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.8076 - val_loss: 0.4042 - val_accuracy: 0.8015\n",
      "Epoch 93/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8077 - val_loss: 0.4066 - val_accuracy: 0.8020\n",
      "Epoch 94/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8041 - val_loss: 0.4051 - val_accuracy: 0.8015\n",
      "Epoch 95/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.8048 - val_loss: 0.4096 - val_accuracy: 0.7980\n",
      "Epoch 96/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8104 - val_loss: 0.4068 - val_accuracy: 0.8020\n",
      "Epoch 97/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8051 - val_loss: 0.3993 - val_accuracy: 0.8030\n",
      "Epoch 98/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4410 - accuracy: 0.8073 - val_loss: 0.4004 - val_accuracy: 0.8035\n",
      "Epoch 99/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8070 - val_loss: 0.4008 - val_accuracy: 0.8010\n",
      "Epoch 100/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.8075 - val_loss: 0.4035 - val_accuracy: 0.8030\n",
      "Epoch 101/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8070 - val_loss: 0.4047 - val_accuracy: 0.8010\n",
      "Epoch 102/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.8035 - val_loss: 0.4021 - val_accuracy: 0.8000\n",
      "Epoch 103/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.8058 - val_loss: 0.4024 - val_accuracy: 0.8005\n",
      "Epoch 104/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4411 - accuracy: 0.8098 - val_loss: 0.4051 - val_accuracy: 0.8010\n",
      "Epoch 105/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8046 - val_loss: 0.4048 - val_accuracy: 0.8005\n",
      "Epoch 106/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4489 - accuracy: 0.8079 - val_loss: 0.4065 - val_accuracy: 0.8000 loss: 0.4559 - accuracy: 0.\n",
      "Epoch 107/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8076 - val_loss: 0.4042 - val_accuracy: 0.8010\n",
      "Epoch 108/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8069 - val_loss: 0.4059 - val_accuracy: 0.7985\n",
      "Epoch 109/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4447 - accuracy: 0.8087 - val_loss: 0.4027 - val_accuracy: 0.8005\n",
      "Epoch 110/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4491 - accuracy: 0.8070 - val_loss: 0.4058 - val_accuracy: 0.8005\n",
      "Epoch 111/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4443 - accuracy: 0.8049 - val_loss: 0.4023 - val_accuracy: 0.8005\n",
      "Epoch 112/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.8091 - val_loss: 0.3998 - val_accuracy: 0.8035\n",
      "Epoch 113/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8083 - val_loss: 0.4006 - val_accuracy: 0.8045\n",
      "Epoch 114/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.8081 - val_loss: 0.4009 - val_accuracy: 0.8050\n",
      "Epoch 115/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4421 - accuracy: 0.8069 - val_loss: 0.3996 - val_accuracy: 0.8045\n",
      "Epoch 116/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4439 - accuracy: 0.8044 - val_loss: 0.3984 - val_accuracy: 0.8035\n",
      "Epoch 117/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.8051 - val_loss: 0.4019 - val_accuracy: 0.8025\n",
      "Epoch 118/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.8065 - val_loss: 0.3992 - val_accuracy: 0.8055\n",
      "Epoch 119/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4442 - accuracy: 0.8106 - val_loss: 0.3986 - val_accuracy: 0.8065\n",
      "Epoch 120/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.8062 - val_loss: 0.4003 - val_accuracy: 0.8030\n",
      "Epoch 121/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8056 - val_loss: 0.4049 - val_accuracy: 0.8005\n",
      "Epoch 122/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.8073 - val_loss: 0.4021 - val_accuracy: 0.8020\n",
      "Epoch 123/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8054 - val_loss: 0.4033 - val_accuracy: 0.8025\n",
      "Epoch 124/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4379 - accuracy: 0.8077 - val_loss: 0.3968 - val_accuracy: 0.8050\n",
      "Epoch 125/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8084 - val_loss: 0.3974 - val_accuracy: 0.8045\n",
      "Epoch 126/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8109 - val_loss: 0.3977 - val_accuracy: 0.8055\n",
      "Epoch 127/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8110 - val_loss: 0.3996 - val_accuracy: 0.8060\n",
      "Epoch 128/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8099 - val_loss: 0.4021 - val_accuracy: 0.8055\n",
      "Epoch 129/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.8064 - val_loss: 0.3987 - val_accuracy: 0.8025\n",
      "Epoch 130/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8062 - val_loss: 0.3981 - val_accuracy: 0.8025\n",
      "Epoch 131/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.8090 - val_loss: 0.3993 - val_accuracy: 0.8040\n",
      "Epoch 132/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4454 - accuracy: 0.8070 - val_loss: 0.4012 - val_accuracy: 0.8030\n",
      "Epoch 133/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4383 - accuracy: 0.8089 - val_loss: 0.3975 - val_accuracy: 0.8035\n",
      "Epoch 134/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4414 - accuracy: 0.8084 - val_loss: 0.3986 - val_accuracy: 0.8040\n",
      "Epoch 135/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8096 - val_loss: 0.3993 - val_accuracy: 0.8035\n",
      "Epoch 136/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8115 - val_loss: 0.4013 - val_accuracy: 0.8045\n",
      "Epoch 137/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4438 - accuracy: 0.8055 - val_loss: 0.3997 - val_accuracy: 0.8030\n",
      "Epoch 138/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4445 - accuracy: 0.8075 - val_loss: 0.4029 - val_accuracy: 0.8030\n",
      "Epoch 139/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4458 - accuracy: 0.8083 - val_loss: 0.4010 - val_accuracy: 0.8050\n",
      "Epoch 140/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4417 - accuracy: 0.8090 - val_loss: 0.3989 - val_accuracy: 0.8020\n",
      "Epoch 141/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4439 - accuracy: 0.8089 - val_loss: 0.3979 - val_accuracy: 0.8045\n",
      "Epoch 142/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.8069 - val_loss: 0.4016 - val_accuracy: 0.8030\n",
      "Epoch 143/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.8106 - val_loss: 0.3949 - val_accuracy: 0.8055\n",
      "Epoch 144/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8124 - val_loss: 0.3960 - val_accuracy: 0.8035\n",
      "Epoch 145/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8076 - val_loss: 0.3960 - val_accuracy: 0.8050\n",
      "Epoch 146/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8086 - val_loss: 0.3987 - val_accuracy: 0.8050\n",
      "Epoch 147/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8089 - val_loss: 0.3973 - val_accuracy: 0.8050\n",
      "Epoch 148/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8117 - val_loss: 0.3994 - val_accuracy: 0.8060\n",
      "Epoch 149/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4441 - accuracy: 0.8098 - val_loss: 0.3957 - val_accuracy: 0.8065\n",
      "Epoch 150/400\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4493 - accuracy: 0.8083 - val_loss: 0.3972 - val_accuracy: 0.8070\n",
      "Epoch 151/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8073 - val_loss: 0.3976 - val_accuracy: 0.8050\n",
      "Epoch 152/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4430 - accuracy: 0.8086 - val_loss: 0.3979 - val_accuracy: 0.8050\n",
      "Epoch 153/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.8102 - val_loss: 0.4002 - val_accuracy: 0.8055\n",
      "Epoch 154/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4467 - accuracy: 0.8074 - val_loss: 0.4002 - val_accuracy: 0.8025\n",
      "Epoch 155/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.8105 - val_loss: 0.3960 - val_accuracy: 0.8030\n",
      "Epoch 156/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4401 - accuracy: 0.8112 - val_loss: 0.3963 - val_accuracy: 0.8035\n",
      "Epoch 157/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.8083 - val_loss: 0.3969 - val_accuracy: 0.8040\n",
      "Epoch 158/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4453 - accuracy: 0.8086 - val_loss: 0.3998 - val_accuracy: 0.8060\n",
      "Epoch 159/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8092 - val_loss: 0.3954 - val_accuracy: 0.8065\n",
      "Epoch 160/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4436 - accuracy: 0.8111 - val_loss: 0.3970 - val_accuracy: 0.8065\n",
      "Epoch 161/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.8098 - val_loss: 0.3992 - val_accuracy: 0.8065\n",
      "Epoch 162/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8111 - val_loss: 0.3958 - val_accuracy: 0.8080\n",
      "Epoch 163/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4355 - accuracy: 0.8116 - val_loss: 0.3898 - val_accuracy: 0.8100\n",
      "Epoch 164/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8108 - val_loss: 0.3917 - val_accuracy: 0.8090\n",
      "Epoch 165/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8119 - val_loss: 0.3929 - val_accuracy: 0.8065\n",
      "Epoch 166/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4357 - accuracy: 0.8133 - val_loss: 0.3943 - val_accuracy: 0.8070\n",
      "Epoch 167/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.8123 - val_loss: 0.3924 - val_accuracy: 0.8085\n",
      "Epoch 168/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4379 - accuracy: 0.8130 - val_loss: 0.3909 - val_accuracy: 0.8080\n",
      "Epoch 169/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4376 - accuracy: 0.8133 - val_loss: 0.3923 - val_accuracy: 0.8080\n",
      "Epoch 170/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4426 - accuracy: 0.8086 - val_loss: 0.3950 - val_accuracy: 0.8075\n",
      "Epoch 171/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.8111 - val_loss: 0.3945 - val_accuracy: 0.8070\n",
      "Epoch 172/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4426 - accuracy: 0.8102 - val_loss: 0.3930 - val_accuracy: 0.8075\n",
      "Epoch 173/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8149 - val_loss: 0.3890 - val_accuracy: 0.8080\n",
      "Epoch 174/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8124 - val_loss: 0.3887 - val_accuracy: 0.8080\n",
      "Epoch 175/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8104 - val_loss: 0.3917 - val_accuracy: 0.8095\n",
      "Epoch 176/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8134 - val_loss: 0.3871 - val_accuracy: 0.8090\n",
      "Epoch 177/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8106 - val_loss: 0.3884 - val_accuracy: 0.8080\n",
      "Epoch 178/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4404 - accuracy: 0.8125 - val_loss: 0.3896 - val_accuracy: 0.8090\n",
      "Epoch 179/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8130 - val_loss: 0.3888 - val_accuracy: 0.8085\n",
      "Epoch 180/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8089 - val_loss: 0.3884 - val_accuracy: 0.8085\n",
      "Epoch 181/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8096 - val_loss: 0.3902 - val_accuracy: 0.8080\n",
      "Epoch 182/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8126 - val_loss: 0.3889 - val_accuracy: 0.8085\n",
      "Epoch 183/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8098 - val_loss: 0.3861 - val_accuracy: 0.8090\n",
      "Epoch 184/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4319 - accuracy: 0.8134 - val_loss: 0.3845 - val_accuracy: 0.8085\n",
      "Epoch 185/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8112 - val_loss: 0.3887 - val_accuracy: 0.8075\n",
      "Epoch 186/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8127 - val_loss: 0.3834 - val_accuracy: 0.8080\n",
      "Epoch 187/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4447 - accuracy: 0.8142 - val_loss: 0.3885 - val_accuracy: 0.8085\n",
      "Epoch 188/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4437 - accuracy: 0.8095 - val_loss: 0.3933 - val_accuracy: 0.8075\n",
      "Epoch 189/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8126 - val_loss: 0.3943 - val_accuracy: 0.8075\n",
      "Epoch 190/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4359 - accuracy: 0.8116 - val_loss: 0.3896 - val_accuracy: 0.8075\n",
      "Epoch 191/400\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4379 - accuracy: 0.8105 - val_loss: 0.3891 - val_accuracy: 0.8080\n",
      "Epoch 192/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.8119 - val_loss: 0.3912 - val_accuracy: 0.8075\n",
      "Epoch 193/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.8111 - val_loss: 0.3872 - val_accuracy: 0.8080\n",
      "Epoch 194/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4371 - accuracy: 0.8114 - val_loss: 0.3850 - val_accuracy: 0.8080\n",
      "Epoch 195/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4371 - accuracy: 0.8131 - val_loss: 0.3873 - val_accuracy: 0.8085\n",
      "Epoch 196/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4375 - accuracy: 0.8131 - val_loss: 0.3865 - val_accuracy: 0.8095\n",
      "Epoch 197/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8146 - val_loss: 0.3885 - val_accuracy: 0.8085\n",
      "Epoch 198/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8150 - val_loss: 0.3838 - val_accuracy: 0.8095\n",
      "Epoch 199/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8152 - val_loss: 0.3819 - val_accuracy: 0.8105\n",
      "Epoch 200/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8106 - val_loss: 0.3839 - val_accuracy: 0.8095\n",
      "Epoch 201/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8166 - val_loss: 0.3845 - val_accuracy: 0.8105\n",
      "Epoch 202/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8125 - val_loss: 0.3860 - val_accuracy: 0.8100\n",
      "Epoch 203/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4389 - accuracy: 0.8130 - val_loss: 0.3863 - val_accuracy: 0.8085\n",
      "Epoch 204/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4357 - accuracy: 0.8164 - val_loss: 0.3843 - val_accuracy: 0.8100\n",
      "Epoch 205/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4350 - accuracy: 0.8115 - val_loss: 0.3843 - val_accuracy: 0.8090\n",
      "Epoch 206/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.8125 - val_loss: 0.3849 - val_accuracy: 0.8090\n",
      "Epoch 207/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8111 - val_loss: 0.3860 - val_accuracy: 0.8100\n",
      "Epoch 208/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8175 - val_loss: 0.3796 - val_accuracy: 0.8095\n",
      "Epoch 209/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4318 - accuracy: 0.8154 - val_loss: 0.3831 - val_accuracy: 0.8095\n",
      "Epoch 210/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4332 - accuracy: 0.8155 - val_loss: 0.3795 - val_accuracy: 0.8115\n",
      "Epoch 211/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.8129 - val_loss: 0.3828 - val_accuracy: 0.8100\n",
      "Epoch 212/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8131 - val_loss: 0.3820 - val_accuracy: 0.8095\n",
      "Epoch 213/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8124 - val_loss: 0.3847 - val_accuracy: 0.8085\n",
      "Epoch 214/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8139 - val_loss: 0.3872 - val_accuracy: 0.8085\n",
      "Epoch 215/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8148 - val_loss: 0.3869 - val_accuracy: 0.8075\n",
      "Epoch 216/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4325 - accuracy: 0.8161 - val_loss: 0.3822 - val_accuracy: 0.8070\n",
      "Epoch 217/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.8114 - val_loss: 0.3850 - val_accuracy: 0.8080\n",
      "Epoch 218/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8142 - val_loss: 0.3831 - val_accuracy: 0.8095\n",
      "Epoch 219/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8148 - val_loss: 0.3854 - val_accuracy: 0.8090\n",
      "Epoch 220/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8131 - val_loss: 0.3870 - val_accuracy: 0.8085\n",
      "Epoch 221/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8117 - val_loss: 0.3876 - val_accuracy: 0.8090\n",
      "Epoch 222/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8140 - val_loss: 0.3819 - val_accuracy: 0.8105\n",
      "Epoch 223/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8109 - val_loss: 0.3839 - val_accuracy: 0.8080\n",
      "Epoch 224/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.8133 - val_loss: 0.3851 - val_accuracy: 0.8085\n",
      "Epoch 225/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.8165 - val_loss: 0.3863 - val_accuracy: 0.8105\n",
      "Epoch 226/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8150 - val_loss: 0.3805 - val_accuracy: 0.8095\n",
      "Epoch 227/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8130 - val_loss: 0.3842 - val_accuracy: 0.8085\n",
      "Epoch 228/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.8126 - val_loss: 0.3842 - val_accuracy: 0.8085\n",
      "Epoch 229/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8142 - val_loss: 0.3826 - val_accuracy: 0.8090\n",
      "Epoch 230/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8130 - val_loss: 0.3856 - val_accuracy: 0.8090\n",
      "Epoch 231/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8167 - val_loss: 0.3794 - val_accuracy: 0.8120\n",
      "Epoch 232/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8141 - val_loss: 0.3794 - val_accuracy: 0.8100\n",
      "Epoch 233/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4324 - accuracy: 0.8124 - val_loss: 0.3799 - val_accuracy: 0.8095\n",
      "Epoch 234/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8140 - val_loss: 0.3810 - val_accuracy: 0.8100\n",
      "Epoch 235/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8141 - val_loss: 0.3778 - val_accuracy: 0.8110\n",
      "Epoch 236/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8133 - val_loss: 0.3823 - val_accuracy: 0.8100\n",
      "Epoch 237/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8144 - val_loss: 0.3790 - val_accuracy: 0.8095\n",
      "Epoch 238/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8125 - val_loss: 0.3823 - val_accuracy: 0.8090\n",
      "Epoch 239/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8110 - val_loss: 0.3825 - val_accuracy: 0.8090\n",
      "Epoch 240/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8152 - val_loss: 0.3812 - val_accuracy: 0.8105\n",
      "Epoch 241/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8133 - val_loss: 0.3788 - val_accuracy: 0.8105\n",
      "Epoch 242/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8131 - val_loss: 0.3818 - val_accuracy: 0.8105\n",
      "Epoch 243/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4323 - accuracy: 0.8150 - val_loss: 0.3810 - val_accuracy: 0.8105\n",
      "Epoch 244/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8130 - val_loss: 0.3843 - val_accuracy: 0.8110\n",
      "Epoch 245/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8135 - val_loss: 0.3843 - val_accuracy: 0.8095\n",
      "Epoch 246/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8119 - val_loss: 0.3843 - val_accuracy: 0.8105\n",
      "Epoch 247/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8167 - val_loss: 0.3838 - val_accuracy: 0.8100\n",
      "Epoch 248/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8106 - val_loss: 0.3861 - val_accuracy: 0.8085\n",
      "Epoch 249/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8123 - val_loss: 0.3837 - val_accuracy: 0.8080\n",
      "Epoch 250/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.8105 - val_loss: 0.3828 - val_accuracy: 0.8080\n",
      "Epoch 251/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4304 - accuracy: 0.8174 - val_loss: 0.3810 - val_accuracy: 0.8090\n",
      "Epoch 252/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.8129 - val_loss: 0.3833 - val_accuracy: 0.8090\n",
      "Epoch 253/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4371 - accuracy: 0.8134 - val_loss: 0.3833 - val_accuracy: 0.8085\n",
      "Epoch 254/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8151 - val_loss: 0.3818 - val_accuracy: 0.8085\n",
      "Epoch 255/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8116 - val_loss: 0.3821 - val_accuracy: 0.8090\n",
      "Epoch 256/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8158 - val_loss: 0.3839 - val_accuracy: 0.8085\n",
      "Epoch 257/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8167 - val_loss: 0.3792 - val_accuracy: 0.8100\n",
      "Epoch 258/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.8105 - val_loss: 0.3800 - val_accuracy: 0.8105\n",
      "Epoch 259/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4340 - accuracy: 0.8165 - val_loss: 0.3781 - val_accuracy: 0.8120\n",
      "Epoch 260/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8098 - val_loss: 0.3837 - val_accuracy: 0.8100\n",
      "Epoch 261/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8114 - val_loss: 0.3819 - val_accuracy: 0.8090\n",
      "Epoch 262/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8125 - val_loss: 0.3835 - val_accuracy: 0.8085\n",
      "Epoch 263/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4396 - accuracy: 0.8130 - val_loss: 0.3873 - val_accuracy: 0.8075\n",
      "Epoch 264/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4347 - accuracy: 0.8119 - val_loss: 0.3828 - val_accuracy: 0.8085\n",
      "Epoch 265/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8155 - val_loss: 0.3838 - val_accuracy: 0.8090\n",
      "Epoch 266/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8121 - val_loss: 0.3806 - val_accuracy: 0.8095\n",
      "Epoch 267/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8111 - val_loss: 0.3859 - val_accuracy: 0.8090\n",
      "Epoch 268/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8138 - val_loss: 0.3830 - val_accuracy: 0.8115\n",
      "Epoch 269/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8109 - val_loss: 0.3806 - val_accuracy: 0.8110\n",
      "Epoch 270/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8126 - val_loss: 0.3808 - val_accuracy: 0.8100\n",
      "Epoch 271/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8117 - val_loss: 0.3844 - val_accuracy: 0.8090\n",
      "Epoch 272/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8144 - val_loss: 0.3816 - val_accuracy: 0.8085\n",
      "Epoch 273/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8126 - val_loss: 0.3797 - val_accuracy: 0.8090\n",
      "Epoch 274/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8151 - val_loss: 0.3767 - val_accuracy: 0.8110\n",
      "Epoch 275/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8117 - val_loss: 0.3825 - val_accuracy: 0.8085\n",
      "Epoch 276/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8136 - val_loss: 0.3779 - val_accuracy: 0.8115\n",
      "Epoch 277/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8149 - val_loss: 0.3788 - val_accuracy: 0.8120\n",
      "Epoch 278/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8140 - val_loss: 0.3815 - val_accuracy: 0.8085\n",
      "Epoch 279/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8134 - val_loss: 0.3807 - val_accuracy: 0.8110\n",
      "Epoch 280/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8167 - val_loss: 0.3831 - val_accuracy: 0.8090\n",
      "Epoch 281/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8144 - val_loss: 0.3809 - val_accuracy: 0.8105\n",
      "Epoch 282/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8173 - val_loss: 0.3808 - val_accuracy: 0.8145\n",
      "Epoch 283/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8106 - val_loss: 0.3796 - val_accuracy: 0.8105\n",
      "Epoch 284/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8142 - val_loss: 0.3808 - val_accuracy: 0.8120\n",
      "Epoch 285/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8138 - val_loss: 0.3828 - val_accuracy: 0.8100\n",
      "Epoch 286/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8130 - val_loss: 0.3799 - val_accuracy: 0.8105\n",
      "Epoch 287/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8156 - val_loss: 0.3751 - val_accuracy: 0.8135\n",
      "Epoch 288/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4289 - accuracy: 0.8156 - val_loss: 0.3755 - val_accuracy: 0.8130\n",
      "Epoch 289/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8114 - val_loss: 0.3791 - val_accuracy: 0.8100\n",
      "Epoch 290/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8130 - val_loss: 0.3809 - val_accuracy: 0.8100\n",
      "Epoch 291/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8127 - val_loss: 0.3814 - val_accuracy: 0.8095\n",
      "Epoch 292/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8121 - val_loss: 0.3801 - val_accuracy: 0.8105\n",
      "Epoch 293/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8148 - val_loss: 0.3797 - val_accuracy: 0.8100\n",
      "Epoch 294/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8108 - val_loss: 0.3798 - val_accuracy: 0.8095\n",
      "Epoch 295/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8121 - val_loss: 0.3807 - val_accuracy: 0.8095\n",
      "Epoch 296/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8124 - val_loss: 0.3810 - val_accuracy: 0.8095\n",
      "Epoch 297/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8146 - val_loss: 0.3803 - val_accuracy: 0.8095\n",
      "Epoch 298/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8109 - val_loss: 0.3803 - val_accuracy: 0.8085\n",
      "Epoch 299/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8130 - val_loss: 0.3840 - val_accuracy: 0.8080\n",
      "Epoch 300/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8121 - val_loss: 0.3823 - val_accuracy: 0.8080\n",
      "Epoch 301/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8167 - val_loss: 0.3824 - val_accuracy: 0.8080\n",
      "Epoch 302/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8139 - val_loss: 0.3837 - val_accuracy: 0.8095\n",
      "Epoch 303/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8111 - val_loss: 0.3840 - val_accuracy: 0.8090\n",
      "Epoch 304/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8123 - val_loss: 0.3852 - val_accuracy: 0.8090\n",
      "Epoch 305/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8109 - val_loss: 0.3828 - val_accuracy: 0.8090\n",
      "Epoch 306/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8133 - val_loss: 0.3821 - val_accuracy: 0.8115\n",
      "Epoch 307/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8173 - val_loss: 0.3752 - val_accuracy: 0.8120\n",
      "Epoch 308/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8105 - val_loss: 0.3809 - val_accuracy: 0.8110\n",
      "Epoch 309/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8139 - val_loss: 0.3845 - val_accuracy: 0.8095\n",
      "Epoch 310/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8099 - val_loss: 0.3842 - val_accuracy: 0.8080\n",
      "Epoch 311/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8121 - val_loss: 0.3842 - val_accuracy: 0.8100\n",
      "Epoch 312/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8120 - val_loss: 0.3839 - val_accuracy: 0.8105\n",
      "Epoch 313/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8104 - val_loss: 0.3832 - val_accuracy: 0.8095\n",
      "Epoch 314/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8109 - val_loss: 0.3842 - val_accuracy: 0.8105\n",
      "Epoch 315/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4327 - accuracy: 0.8152 - val_loss: 0.3804 - val_accuracy: 0.8105\n",
      "Epoch 316/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.8138 - val_loss: 0.3808 - val_accuracy: 0.8115\n",
      "Epoch 317/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8108 - val_loss: 0.3837 - val_accuracy: 0.8090\n",
      "Epoch 318/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8146 - val_loss: 0.3794 - val_accuracy: 0.8110\n",
      "Epoch 319/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8120 - val_loss: 0.3849 - val_accuracy: 0.8105\n",
      "Epoch 320/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8146 - val_loss: 0.3767 - val_accuracy: 0.8120\n",
      "Epoch 321/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8144 - val_loss: 0.3795 - val_accuracy: 0.8120\n",
      "Epoch 322/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4284 - accuracy: 0.8171 - val_loss: 0.3748 - val_accuracy: 0.8155\n",
      "Epoch 323/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.8116 - val_loss: 0.3805 - val_accuracy: 0.8095\n",
      "Epoch 324/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4376 - accuracy: 0.8133 - val_loss: 0.3796 - val_accuracy: 0.8095\n",
      "Epoch 325/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8145 - val_loss: 0.3848 - val_accuracy: 0.8095\n",
      "Epoch 326/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.8141 - val_loss: 0.3796 - val_accuracy: 0.8140\n",
      "Epoch 327/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4264 - accuracy: 0.8159 - val_loss: 0.3748 - val_accuracy: 0.8130\n",
      "Epoch 328/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.8112 - val_loss: 0.3838 - val_accuracy: 0.8090\n",
      "Epoch 329/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.8095 - val_loss: 0.3833 - val_accuracy: 0.8090\n",
      "Epoch 330/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4314 - accuracy: 0.8115 - val_loss: 0.3778 - val_accuracy: 0.8090\n",
      "Epoch 331/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4356 - accuracy: 0.8145 - val_loss: 0.3799 - val_accuracy: 0.8095\n",
      "Epoch 332/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4327 - accuracy: 0.8114 - val_loss: 0.3784 - val_accuracy: 0.8130\n",
      "Epoch 333/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4329 - accuracy: 0.8133 - val_loss: 0.3801 - val_accuracy: 0.8130\n",
      "Epoch 334/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4335 - accuracy: 0.8160 - val_loss: 0.3790 - val_accuracy: 0.8125\n",
      "Epoch 335/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.8126 - val_loss: 0.3818 - val_accuracy: 0.8100\n",
      "Epoch 336/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4260 - accuracy: 0.8134 - val_loss: 0.3748 - val_accuracy: 0.8155\n",
      "Epoch 337/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4347 - accuracy: 0.8142 - val_loss: 0.3779 - val_accuracy: 0.8150\n",
      "Epoch 338/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8136 - val_loss: 0.3817 - val_accuracy: 0.8120\n",
      "Epoch 339/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8149 - val_loss: 0.3812 - val_accuracy: 0.8115\n",
      "Epoch 340/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4335 - accuracy: 0.8150 - val_loss: 0.3792 - val_accuracy: 0.8110\n",
      "Epoch 341/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8134 - val_loss: 0.3800 - val_accuracy: 0.8115\n",
      "Epoch 342/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8142 - val_loss: 0.3783 - val_accuracy: 0.8140\n",
      "Epoch 343/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8112 - val_loss: 0.3816 - val_accuracy: 0.8100\n",
      "Epoch 344/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8141 - val_loss: 0.3825 - val_accuracy: 0.8105\n",
      "Epoch 345/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8145 - val_loss: 0.3797 - val_accuracy: 0.8105\n",
      "Epoch 346/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8133 - val_loss: 0.3807 - val_accuracy: 0.8110\n",
      "Epoch 347/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8110 - val_loss: 0.3791 - val_accuracy: 0.8095\n",
      "Epoch 348/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8133 - val_loss: 0.3826 - val_accuracy: 0.8130\n",
      "Epoch 349/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.8127 - val_loss: 0.3801 - val_accuracy: 0.8115\n",
      "Epoch 350/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4370 - accuracy: 0.8121 - val_loss: 0.3819 - val_accuracy: 0.8110\n",
      "Epoch 351/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8165 - val_loss: 0.3771 - val_accuracy: 0.8120\n",
      "Epoch 352/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8165 - val_loss: 0.3763 - val_accuracy: 0.8130\n",
      "Epoch 353/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8180 - val_loss: 0.3751 - val_accuracy: 0.8130\n",
      "Epoch 354/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8126 - val_loss: 0.3783 - val_accuracy: 0.8105\n",
      "Epoch 355/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8158 - val_loss: 0.3773 - val_accuracy: 0.8110\n",
      "Epoch 356/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8149 - val_loss: 0.3773 - val_accuracy: 0.8130\n",
      "Epoch 357/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8115 - val_loss: 0.3816 - val_accuracy: 0.8105\n",
      "Epoch 358/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8164 - val_loss: 0.3792 - val_accuracy: 0.8140\n",
      "Epoch 359/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8145 - val_loss: 0.3790 - val_accuracy: 0.8110\n",
      "Epoch 360/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8115 - val_loss: 0.3779 - val_accuracy: 0.8110\n",
      "Epoch 361/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8173 - val_loss: 0.3776 - val_accuracy: 0.8115\n",
      "Epoch 362/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4348 - accuracy: 0.8114 - val_loss: 0.3786 - val_accuracy: 0.8100\n",
      "Epoch 363/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4370 - accuracy: 0.8130 - val_loss: 0.3786 - val_accuracy: 0.8100\n",
      "Epoch 364/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8127 - val_loss: 0.3797 - val_accuracy: 0.8115\n",
      "Epoch 365/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8165 - val_loss: 0.3803 - val_accuracy: 0.8125\n",
      "Epoch 366/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8146 - val_loss: 0.3788 - val_accuracy: 0.8115\n",
      "Epoch 367/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4362 - accuracy: 0.8148 - val_loss: 0.3781 - val_accuracy: 0.8125\n",
      "Epoch 368/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8146 - val_loss: 0.3812 - val_accuracy: 0.8105\n",
      "Epoch 369/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8125 - val_loss: 0.3779 - val_accuracy: 0.8100\n",
      "Epoch 370/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8116 - val_loss: 0.3804 - val_accuracy: 0.8105\n",
      "Epoch 371/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8133 - val_loss: 0.3804 - val_accuracy: 0.8100\n",
      "Epoch 372/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8167 - val_loss: 0.3805 - val_accuracy: 0.8110\n",
      "Epoch 373/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8086 - val_loss: 0.3868 - val_accuracy: 0.8090\n",
      "Epoch 374/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8129 - val_loss: 0.3772 - val_accuracy: 0.8110\n",
      "Epoch 375/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8130 - val_loss: 0.3790 - val_accuracy: 0.8115\n",
      "Epoch 376/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8106 - val_loss: 0.3794 - val_accuracy: 0.8105\n",
      "Epoch 377/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4345 - accuracy: 0.8140 - val_loss: 0.3799 - val_accuracy: 0.8120\n",
      "Epoch 378/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8138 - val_loss: 0.3836 - val_accuracy: 0.8105\n",
      "Epoch 379/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8127 - val_loss: 0.3836 - val_accuracy: 0.8115\n",
      "Epoch 380/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8121 - val_loss: 0.3806 - val_accuracy: 0.8110\n",
      "Epoch 381/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8139 - val_loss: 0.3789 - val_accuracy: 0.8115\n",
      "Epoch 382/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8136 - val_loss: 0.3775 - val_accuracy: 0.8135\n",
      "Epoch 383/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4371 - accuracy: 0.8112 - val_loss: 0.3794 - val_accuracy: 0.8135\n",
      "Epoch 384/400\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4368 - accuracy: 0.8120 - val_loss: 0.3821 - val_accuracy: 0.8095\n",
      "Epoch 385/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8125 - val_loss: 0.3831 - val_accuracy: 0.8100\n",
      "Epoch 386/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8123 - val_loss: 0.3807 - val_accuracy: 0.8105\n",
      "Epoch 387/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8155 - val_loss: 0.3816 - val_accuracy: 0.8100\n",
      "Epoch 388/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8144 - val_loss: 0.3818 - val_accuracy: 0.8090\n",
      "Epoch 389/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8148 - val_loss: 0.3796 - val_accuracy: 0.8120\n",
      "Epoch 390/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8154 - val_loss: 0.3831 - val_accuracy: 0.8110\n",
      "Epoch 391/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8135 - val_loss: 0.3751 - val_accuracy: 0.8125\n",
      "Epoch 392/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8194 - val_loss: 0.3781 - val_accuracy: 0.8140\n",
      "Epoch 393/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8171 - val_loss: 0.3758 - val_accuracy: 0.8125\n",
      "Epoch 394/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8126 - val_loss: 0.3797 - val_accuracy: 0.8100\n",
      "Epoch 395/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8175 - val_loss: 0.3756 - val_accuracy: 0.8130\n",
      "Epoch 396/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8117 - val_loss: 0.3786 - val_accuracy: 0.8095\n",
      "Epoch 397/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8131 - val_loss: 0.3791 - val_accuracy: 0.8120\n",
      "Epoch 398/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8092 - val_loss: 0.3807 - val_accuracy: 0.8100\n",
      "Epoch 399/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8160 - val_loss: 0.3770 - val_accuracy: 0.8130\n",
      "Epoch 400/400\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8117 - val_loss: 0.3794 - val_accuracy: 0.8095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e60466d400>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.fit(xtrain, ytrain, epochs=400, validation_data=(xtest,ytest) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48204a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.649887</td>\n",
       "      <td>0.731750</td>\n",
       "      <td>0.536624</td>\n",
       "      <td>0.7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.568067</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.506156</td>\n",
       "      <td>0.7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.536281</td>\n",
       "      <td>0.795750</td>\n",
       "      <td>0.494398</td>\n",
       "      <td>0.7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.518422</td>\n",
       "      <td>0.797125</td>\n",
       "      <td>0.489508</td>\n",
       "      <td>0.7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509147</td>\n",
       "      <td>0.797750</td>\n",
       "      <td>0.484242</td>\n",
       "      <td>0.7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.439449</td>\n",
       "      <td>0.811750</td>\n",
       "      <td>0.378611</td>\n",
       "      <td>0.8095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.437971</td>\n",
       "      <td>0.813125</td>\n",
       "      <td>0.379139</td>\n",
       "      <td>0.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.436750</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>0.380731</td>\n",
       "      <td>0.8100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.432678</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.377022</td>\n",
       "      <td>0.8130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.439962</td>\n",
       "      <td>0.811750</td>\n",
       "      <td>0.379362</td>\n",
       "      <td>0.8095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    0.649887  0.731750  0.536624        0.7925\n",
       "1    0.568067  0.784375  0.506156        0.7925\n",
       "2    0.536281  0.795750  0.494398        0.7925\n",
       "3    0.518422  0.797125  0.489508        0.7925\n",
       "4    0.509147  0.797750  0.484242        0.7925\n",
       "..        ...       ...       ...           ...\n",
       "395  0.439449  0.811750  0.378611        0.8095\n",
       "396  0.437971  0.813125  0.379139        0.8120\n",
       "397  0.436750  0.809250  0.380731        0.8100\n",
       "398  0.432678  0.816000  0.377022        0.8130\n",
       "399  0.439962  0.811750  0.379362        0.8095\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses3=pd.DataFrame(d3.history.history)\n",
    "losses3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "764f4be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd2a6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
